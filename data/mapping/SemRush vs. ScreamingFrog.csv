Issue Name Contains - SemRush,Issue Type - SemRush,Issue category - SemRush,Issue description - SemRush,How to fix - SemRush,Issue Name - ScreamingFrog,Issue Type - ScreamingFrog,Issue Priority - ScreamingFrog,Description ScreamingFrog,How To Fix - ScreamingFrog,sf_config_file,sf_export_tabs
NA,NA,NA,NA,NA,Canonicals: Multiple Conflicting,Issue,High,"Pages with multiple canonicals set for a URL that have different URLs specified (via either multiple link elements, HTTP header, or both combined).

This can lead to unpredictability, as there should only be a single canonical URL set by a single implementation (link element, or HTTP header) for a page.","Specify a single canonical URL using a single approach (link element, or HTTP header) for every page to avoid any potential mix ups.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Canonicals: Non-Indexable Canonical,Issue,High,"Pages with a canonical URL that is non-indexable. This will include canonicals which are blocked by robots.txt, no response, redirect (3XX), client error (4XX), server error (5XX), are 'noindex' or 'canonicalised' themselves. This means the search engines are being instructed to consolidate indexing and link signals to a non-indexable page, which often leads to them ignoring the canonical, but may also lead to unpredictability in indexing and ranking. Export pages, their canonicals and status codes via 'Reports > Canonicals > Non-Indexable Canonicals'.","Ensure canonical URLs are to accurate indexable pages to avoid them being ignored by search engines, and any potential indexing or ranking unpredictability.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Canonicals: Invalid Attribute In Annotation,Issue,High,"Pages with a rel=”canonical” annotation that includes an alternate version using an hreflang, lang, media, or type attribute.

Adding certain attributes to the link element changes the meaning of the annotation to denote a different device or language version. These annotations are ignored and not used for canonicalisation by Google.","Use separate appropriate link annotations to specify alternate versions of a page.

Google supports explicit rel canonical link annotations and they should not contain hreflang, lang, media, and type attributes.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Canonicals: Contains Fragment URL,Issue,High,"Pages with a rel=""canonical"" that includes a fragment URL in the href attribute. Google generally doesn't support fragment URLs. These annotations are ignored and not used for canonicalisation by Google.","Remove fragment URLs from canonical annotations and ensure they are to accurate indexable pages to avoid them being ignored by search engines, and any potential indexing or ranking unpredictability.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Canonicals: Outside <head>,Issue,High,"Pages with a canonical link element that is outside of the <head> element in the HTML.

The canonical link element should be within the <head> element, or search engines will ignore it.",Ensure canonical link elements are in the <head> element of a page’s HTML to be considered by search engines.,default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Canonicals: Canonicalised,Warnings,High,"Pages that have a canonical to a different URL. The URL is 'canonicalised' to another location. This means the search engines are being instructed to not index the page, and the indexing and linking properties should be consolidated to the URL in the canonical.","These URLs should be reviewed carefully to ensure the indexing and link signals are being consolidated to the correct URL. In a perfect world, a website wouldn't need to canonicalise any URLs as only canonical versions would be linked to internally on a website, but often they are required due to various circumstances outside of control, and to prevent duplicate content. Update internal links to canonical versions of URLs where possible.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Canonicals: Missing,Warnings,Medium,"Pages that have no canonical URL present either as a link element, or via HTTP header. If a page doesn't indicate a canonical URL, Google will identify what they think is the best version or URL. This can lead to ranking unpredictability when there are multiple versions discovered, and hence generally all URLs should specify a canonical version",Specify a canonical URL for every page to avoid any potential ranking unpredictability if multiple versions of the same page are discovered on different URLs.,default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Canonicals: Unlinked,Warnings,Medium,"URLs that are only discoverable via rel=”canonical” and are not linked to via hyperlinks on the website.

This might be a sign of a problem with internal linking, or the URLs contained in the canonical.","Review the URLs contained in the rel=”canonical” and ensure they are linked to across the website where appropriate.

Canonical versions of URLs should be linked to, rather than non-canonical URLs. Incorrect canonicals should be updated to accurate canonical versions.",default_config.seospiderconfig,Internal:All
Multiple canonical URLs,Error,"Indexability, Canonicalization","Multiple rel=”canonical” tags with different URLs specified for the same page confuse search engines and make it almost impossible for them to identify which URL is the actual canonical page. As a result, search engines will likely ignore all the canonical elements or pick the wrong one. That’s why it is recommended that you specify no more than one rel=”canonical” for a page.",Remove all canonical URLs except the one that you’d like to serve as the actual canonical page.,Canonicals: Multiple,Warnings,Low,"Pages with multiple canonicals set for a URL (either multiple link elements, HTTP header, or both combined).

This can lead to unpredictability, as there should only be a single canonical URL set by a single implementation (link element, or HTTP header) for a page and might lead to mix ups.","Specify a single canonical URL using a single approach (link element, or HTTP header) for every page to avoid any potential mix ups.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Canonicals: Canonical Is Relative,Warnings,Low,"Pages that have a relative rather than absolute rel=”canonical” link tag.

While the <link> tag, like many HTML tags, accepts both relative and absolute URLs, it’s easy to make subtle mistakes with relative paths that could cause indexing related issues.",Google recommend using absolute paths rather than relative paths for the rel=”canonical” link tag.,default_config.seospiderconfig,Internal:All
Broken canonical URLs,Error,"HTTP Status, Indexability, Canonicalization","By setting a rel=""canonical"" element on your page, you can inform search engines of which version of a page you want to show up in search results. When using canonical tags, it is important to make sure that the URL you include in your rel=""canonical"" element leads to a page that actually exists. Canonical links that lead to non-existent webpages complicate the process of crawling and indexing your content and, as a result, decrease crawling efficiency and lead to unnecessary crawl budget waste.","Review all broken canonical links. If a canonical URL applies to a non-existent webpage, remove it or replace it with another resourc",NA,NA,NA,NA,NA,default_config.seospiderconfig,Internal:All
Neither canonical URL nor 301 redirect from HTTP homepage,Error,"Duplicates, Indexability, Canonicalization","If you're running both HTTP and HTTPS versions of your homepage, it is very important to make sure that their coexistence doesn't impede your SEO. Search engines are not able to figure out which page to index and which one to prioritize in search results. As a result, you may experience a lot of problems, including pages competing with each other, traffic loss and poor placement in search results. To avoid these issues, you must instruct search engines to only index the HTTPS version.","Do either of the following:
- Redirect your HTTP page to the HTTPS version via a 301 redirect
- Mark up your HTTPS version as the preferred one by adding a rel=""canonical"" to your HTTP pages",NA,NA,NA,NA,NA,default_config.seospiderconfig,Internal:All
Missing h1,Warnings,"Meta tags, Indexability","While less important than <title> tags, h1 headings still help define your page’s topic for search engines and users. If an <h1> tag is empty or missing, search engines may place your page lower than they would otherwise. Besides, a lack of an <h1> tag breaks your page’s heading hierarchy, which is not SEO friendly.","Provide a concise, relevant h1 heading for each of your page.",H1: Missing,Issue,Medium,"Pages which have a missing <h1>, the content is empty or has a whitespace. The <h1> should describe the main title and purpose of the page and are considered to be one of the stronger on-page ranking signals.","Ensure important pages have concise, descriptive and unique headings to help users, and enable search engines to score and rank the page for relevant search queries.",default_config.seospiderconfig,Internal:All
Multiple h1 tags,Notices,"Meta tags, Indexability","Although multiple <h1> tags are allowed in HTML5, we still do not recommend that you use more than one <h1> tag per page. Including multiple <h1> tags may confuse users.",Use multiple <h2>-<h6> tags instead of an <h1>.,H1: Multiple,Warnings,Medium,"Pages which have multiple <h1>s. While this is not strictly an issue because HTML5 standards allow multiple <h1>s on a page, there are some problems with this modern approach in terms of usability. It's advised to use heading rank (h1-h6) to convey document structure. The classic HTML4 standard defines there should only be a single <h1> per page, and this is still generally recommended for users and SEO.","Consider updating the HTML to include a single <h1> on each page, and utilising the full heading rank between (h2 - h6) for additional headings.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,H1: Alt Text in H1,Warnings,Low,"Pages which have image alt text within an <h1>. This can be because text within the image is considered as the main heading on the page, or due to inappropriate mark-up. Some CMS templates will automatically include an <h1> around a logo across a website. While there are strong arguments that text rather than alt text should be used for headings, search engines may understand alt text within an <h1> as part of the <h1> and score accordingly.",Review whether the use of image alt text within the <h1> is appropriate for the website and consider using on-page text instead.,default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,H1: Non-Sequential,Warnings,Low,"Pages with an <h1> that is not the first heading on the page. Heading elements should be in a logical sequentially-descending order. The purpose of heading elements is to convey the structure of the page and they should be in logical order from <h1> to <h6>, which helps navigating the page and users that rely on assistive technologies.","Ensure the <h1> is the first heading on the page. Headings should be in a logical sequential order from <h1> to <h6>. Review and update page heading levels so they are descending in order, for example the first heading level should be an <h1>, and this should be followed by an <h2>.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,H1: Duplicate,Opportunity,Low,"Pages which have duplicate <h1>s. It's important to have distinct, unique and useful main headings. If every page has the same <h1>, then it can make it more challenging for users and the search engines to understand one page from another.","Update duplicate <h1>s as necessary, so important pages contain a unique and descriptive <h1> for users and search engines. If these are duplicate pages, then fix the duplicated pages by linking to a single version, and redirect or use canonicals where appropriate.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,H1: Over 70 Characters,Opportunity,Low,"Pages which have <h1>s over the configured length. There is no hard limit for characters in an <h1>, however they should be clear and concise for users and long headings might be less helpful","Write concise <h1>s for users, including target keywords where natural for users - without keyword stuffing.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,H2: Missing,Warnings,Low,"Pages which have a missing <h2>, the content is empty or has a whitespace. The <h2> heading is often used to describe sections or topics within a document. They act as signposts for the user, and can help search engines understand the page.",Consider using logical and descriptive <h2>s on important pages that help the user and search engines better understand the page.,default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,H2: Multiple,Warnings,Low,"Pages which have multiple <h2>s.

This is not an issue as HTML standards allow multiple <h2>’s when used in a logical hierarchical heading structure.

However, this filter can help you quickly scan to review if they are used appropriately.","Ensure <h2>s are used in a logical hierarchical heading structure, and update where appropriate utilising the full heading rank between (h3 – h6) for additional headings.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,H2: Non-Sequential,Warnings,Low,"Pages with an <h2> that is not the second heading level after the <h1> on the page. Heading elements should be in a logical sequentially-descending order. The purpose of heading elements is to convey the structure of the page and they should be in logical order from <h1> to <h6>, which helps navigating the page and users that rely on assistive technologies.","Ensure the <h2> is the second heading on the page. Headings should be in a logical sequential order from <h1> to <h6>. Review and update page heading levels so they are descending in order, for example the heading element following an <h1> should be an <h2>, rather than an <h3>.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,H2: Duplicate,Opportunity,Low,"Pages which have duplicate <h2>s.

It’s important to have distinct, unique and useful pages. If every page has the same <h2>, then it can make it more challenging for users and the search engines to understand one page from another.","Update duplicate <h2>s as necessary, so important pages contain a unique and descriptive <h2> for users and search engines.

If these are duplicate pages, then fix the duplicated pages by linking to a single version, and redirect or use canonicals where appropriate.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,H2: Over 70 Characters,Opportunity,Low,"Pages which have <h2>s over 70 characters in length.

There is no hard limit for characters in an <h2>, however they should be clear and concise for users and long headings might be less helpful.","Write concise <h2>s for users, including target keywords where natural for users – without keyword stuffing.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Images: Missing Alt Text,Issue,Low,"Images that have an alt attribute, but are missing alt text. Click the address of the image and then the 'Image Details' tab in the lower window pane to view which pages have the image on them, and are missing alt text. Images should have descriptive alternative text about its purpose, which helps the blind and visually impaired, and the search engines understand it and its relevance to the web page.","Include descriptive alt text for images to help users and the search engines understand them better. Where possible, decorative images should be provided using CSS background images or alternatively a null (empty) alt text should be provided (alt="""") so that they can be ignored by assistive technologies, such as screen readers.",default_config.seospiderconfig,Internal:All
Missing ALT attributes,Warnings,"Meta tags, Indexability","Alt attributes within <img> tags are used by search engines to understand the contents of your images. If you neglect alt attributes, you may miss the chance to get a better placement in search results because alt attributes allow you to rank in image search results.
Not using alt attributes also negatively affects the experience of visually impaired users and those who have disabled images in their browsers.
For more information, please see these articles: Using ALT attributes smartly and Google Image Publishing Guidelines","Specify ‪‬‬a relevant alternative attribute inside an <img> tag for each image on your website, e.g., ""<img src=""mylogo.png"" alt=""This is my company logo"">"".",Images: Missing Alt Attribute,Issue,Low,"Images that are missing an alt attribute all together. Click the address (URL) of the image and then the 'Image Details' tab in the lower window pane to view which pages have the image on, and are missing alt attributes. All images should contain an alt attribute with descriptive text, or blank when it's a decorative image.","Include alt attributes with descriptive alt text for images to help users and the search engines understand them better. Where possible, decorative images should be provided using CSS background images or alternatively a null (empty) alt text should be provided (alt="""") so that they can be ignored by assistive technologies, such as screen readers.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Images: Background Images,Warnings,Low,"CSS background and dynamically loaded images discovered across the website, which should be used for non-critical and decorative purposes.

Background images are not typically indexed by Google and browsers do not provide alt attributes or text on background images to assistive technology.","Review CSS background images discovered and ensure they are correctly used for decorative images and styling.

If the image contains information critical to understanding the page’s overall purpose or are important for indexing, then Google recommended using <img> tags.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Images: Over 100 kb,Opportunity,Medium,"Large images over a size threshold. Page speed is extremely important for users and SEO and often large resources such as images are one of the most common issues that slow down web pages. This filter simply acts as a general rule of thumb to help identify images that are fairly large in file size and may take longer to load. These should be considered for optimisation, alongside opportunities identified in the PageSpeed tab which uses the PSI API and Lighthouse to audit speed. This can help identify images that haven't been optimised in size, load offscreen, are unoptimised etc.","Uncompressed images bloat pages with unnecessary bytes, so ensure images are optimised with compression, properly scaled, and using the best image format to reduce file size where possible.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Images: Alt Text Over 100 Characters,Opportunity,Low,"Images which have one instance of alt text over a threshold of characters in length. This is not strictly an issue, however image alt text should be concise and descriptive. It should not be used to stuff lots of keywords or paragraphs of text onto a page.",Write concise alt text that's helpful for users and search engines - without keyword stuffing.,default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Images: Incorrectly Sized Images,Opportunity,Low,"Images identified where their real dimensions (WxH) do not match the display dimensions when rendered.

If there is an estimated 4kb file size difference or more, the image is flagged for potential optimisation.

In particular, this can help identify oversized images, which can contribute to poor page load speed. It can also help identify smaller sized images, that are being stretched when rendered.","Ideally images should not be larger than the version that’s rendered on the user’s screen. Anything larger than that results in wasted bytes and slows down page load time.

Use responsive images to serve appropriately sized images for all viewports.

For any images that are smaller than the rendered version, provide appropriately-sized versions to avoid stretched images for users.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Images: Missing Size Attributes,Opportunity,Low,Image elements without dimensions (width and height size attributes) specified in the HTML. This can cause large layout shifts as the page loads and be frustrating experience for users. It is one of the major reasons that contributes to a high Cumulative Layout Shift (CLS).,"Define all image sizes as their native size using width and height attributes in the HTML. This allows the browser to calculate enough space for each image before it loads, avoiding large layout shifts.",default_config.seospiderconfig,Internal:All
Broken external links,Warnings,"HTTP Status, Crawlability",A broken external image is an image that can't be displayed because it no longer exists or because its URL is misspelled. Having too many broken external images negatively affects user experience and may be a signal to search engines that your website is poorly coded or maintained.,"To fix a broken external image, perform one of the following:
- If an image was deleted or damaged, replace it with a new one
- If an image is no longer needed, simply remove it from your page's code
- If an image moved to a different location and you know its new address, change its URL",NA,NA,NA,NA,NA,default_config.seospiderconfig,Internal:All
Broken internal images,Error,"HTTP Status, Crawlability","An internal broken image is an image that can't be displayed because it no longer exists, its URL is misspelled, or because the file path is not valid. Broken images may jeopardize your search rankings because they provide a poor user experience and signal to search engines that your page is low quality.","To fix a broken internal image, perform one of the following:
- If an image is no longer located in the same location, change its URL
- If an image was deleted or damaged, replace it with a new one
- If an image is no longer needed, simply remove it from your page's code",NA,NA,NA,NA,NA,default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Links: Outlinks To Localhost,Issue,High,"Pages that contain links that reference localhost or the 127.0.0.1 loopback address.

Localhost is the address of the local computer, which is used in development to view a site in a browser without being connected to the internet.

These links will not work for users on a live website.",Review the ‘Outlinks’ tab for the localhost and/or 127.0.0.1 loopback address links and update them to the correct publicly available URL address.,default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Links: Pages Without Internal Outlinks,Warnings,High,"Pages that do not contain links to other internal pages. This can mean there are no links to other pages. However, it is also often due to the use of JavaScript, where links are not present in the raw HTML and are only in the rendered HTML after JavaScript has been processed. Enable JavaScript rendering mode ('Config > Spider > Rendering') to crawl pages with links that are only client-side in the rendered HTML. If there are no links that use an <a> tag with an href attribute to other internal pages, the search engines and the SEO Spider will have trouble discovering and indexing them.","Review the pages and whether there are links in the raw or rendered HTML. Switch to JavaScript rendering mode if links are only in the rendered HTML. While Google is able to render pages and see client-side only links, consider including important links server side in the raw HTML. For pages that simply don't link to any other internal pages, consider linking to other pages to help users continue in their journey and pass PageRank onwards.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Links: Non-Indexable Page Inlinks Only,Warnings,High,"Indexable pages that are only linked to from pages that are non-indexable, which includes noindex, canonicalised or robots.txt disallowed pages. Pages with noindex and links from them will initially be crawled, but noindex pages will be removed from the index and be crawled less over time. Links from these pages may also be crawled less and it has been debated by Googlers whether links will continue to be counted at all. Links from canonicalised pages can be crawled initially, but PageRank may not flow as expected if indexing and link signals are passed to another page as indicated in the canonical. This may impact discovery and ranking. Robots.txt pages can't be crawled, so links from these pages will not be seen. Robots.txt disallowed pages will only be reported here if 'ignore robots.txt but report status' is selected via 'Config > Robots.txt > Settings'. The pages that are non-indexable and link to the pages in this issue can be viewed via the 'Inlinks' tab. Export in bulk via 'Bulk Export > Links > Non-Indexable Page Inlinks Only'.","Ensure you link to important pages from indexable pages to avoid any uncertainty in discovery, indexing and ranking. Consider whether the non-indexable pages linking to these pages should be non-indexable.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Links: Internal Nofollow Outlinks,Warnings,Low,"Pages that use rel=""nofollow"" on internal outlinks. Links with nofollow link attributes will generally not be followed by search engines. Remember that the linked pages may be found through other means, such as other followed links, or XML Sitemaps etc. Nofollow outlinks can be seen in the 'Outlinks' tab with the 'All Link Types' filter set to 'Hyperlinks', where the 'Follow' column is 'False'. Export in bulk via 'Bulk Export > Links > Internal Nofollow Outlinks'.","Review the use of rel=""nofollow"" on internal links. These might be valid to URLs that ideally wouldn't be crawled, or they could be by mistake. Remove the nofollow link attribute to important URLs you wish to be crawled, indexed and receive PageRank.",default_config.seospiderconfig,Internal:All
Too many on-page links,Warnings,"Links, Crawlability","This issue is triggered if a webpage contains more than 3,000 links. As a rule, search engines process as many on-page links as they consider necessary for a particular website. However, placing more than 3,000 links on a webpage can make your page look low-quality and even spammy to search engines, which may cause your page to drop in rankings or not to show up in search results at all. Having too many on-page links is also bad for user experience.","Review all pages that contain more than 3,000 links and delete unnecessary links.
You can also use the Internal Linking report to check your internal linking.",Links: Pages With High External Outlinks,Warnings,Low,"Pages that have a high number of followed external outlinks on them based upon the 'High External Outlinks' preferences under 'Config > Spider > Preferences'. External outlinks are hyperlinks to another subdomain or domain (depending on your configuration). This might be completely valid, such as linking to another part of the same root domain, or linking to other useful websites. External followed outlinks can be seen in the 'Outlinks' tab, with the 'All Link Types' filter set to 'Hyperlinks' where the 'Follow' column is 'True'.","Review followed external outlinks to ensure they are to credible, trusted and relevant websites that are useful to your users.",default_config.seospiderconfig,Internal:All
Too many on-page links,Warnings,"Links, Crawlability","This issue is triggered if a webpage contains more than 3,000 links. As a rule, search engines process as many on-page links as they consider necessary for a particular website. However, placing more than 3,000 links on a webpage can make your page look low-quality and even spammy to search engines, which may cause your page to drop in rankings or not to show up in search results at all. Having too many on-page links is also bad for user experience.","Review all pages that contain more than 3,000 links and delete unnecessary links.
You can also use the Internal Linking report to check your internal linking.",Links: Pages With High Internal Outlinks,Warnings,Low,"Pages that have a high number of followed internal outlinks on them based upon the ‘High Internal Outlinks’ preferences under ‘Config > Spider > Preferences’.

Internal outlinks are hyperlinks to the same subdomain or domain (depending on your configuration).

Links are used by users to navigate a website, while the search engines use them to discover and rank pages. Too many links can reduce usability, and reduce the amount of PageRank distributed to each page.",Review followed internal outlinks to ensure they provide great usability to users navigating the website and unimportant pages are not being linked to unnecessarily.,default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Links: Follow & Nofollow Internal Inlinks To Page,Warnings,Low,"Pages that have both rel=""nofollow"" and follow links to them from other pages. Links marked with nofollow link attributes will generally not be followed by search engines. Links without a nofollow link attribute will generally be followed. So inconsistent use of links that are follow and nofollow might be a sign of an issue or mistake, or something that can be ignored. Nofollow and follow inlinks can be seen in the 'Inlinks' tab with the 'All Link Types' filter set to 'Hyperlinks', where the 'Follow' column is 'True' and 'False'. Export in bulk via 'Bulk Export > Links > Follow & Nofollow Internal Inlinks To Page'.","Review the consistency of the use of rel=""nofollow"" on internal links. These might be valid to URLs that ideally wouldn't be crawled, or they could be by mistake. Remove the nofollow link attribute to important URLs you wish to be crawled, indexed and receive PageRank. Add nofollow to any links that are incorrectly missing it.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Links: Internal Nofollow Inlinks Only,Warnings,Low,"Pages that only have rel=""nofollow"" links to them from other pages. Links marked with nofollow link attributes will generally not be followed by search engines, so this can impact discovery and indexing of a page. Nofollow inlinks can be seen in the 'Inlinks' tab with the 'All Link Types' filter set to 'Hyperlinks', where the 'Follow' column is 'False'. Export in bulk via 'Bulk Export > Links > Internal Nofollow Inlinks Only'.","Review the use of rel=""nofollow"" on internal links to pages. These might be valid to URLs that ideally wouldn't be crawled, or they could be by mistake. Remove the nofollow link attribute to important URLs you wish to be crawled, indexed and receive PageRank.",default_config.seospiderconfig,Internal:All
Page crawl depth,Notices,"Links, Crawlability","A page's crawl depth is the number of clicks required for users and search engine crawlers to reach it via its corresponding homepage. From an SEO perspective, an excessive crawl depth may pose a great threat to your optimization efforts, as both crawlers and users are less likely to reach deep pages.
For this reason, pages that contain important content should be no more than 3 clicks away from your homepage.","Make sure that pages with important content can be reached within a few clicks.
If any of them are buried too deep in your site, consider changing your internal link architecture.",Links: Pages With High Crawl Depth,Opportunity,Medium,"Pages that have a high crawl depth from the start page of the crawl based upon the 'Crawl Depth' preferences under 'Config > Spider > Preferences'. Broadly, pages that are linked directly from popular pages, such as the homepage, are passed more PageRank which can help them perform better organically. Pages much deeper in the website can often be passed less PageRank, and subsequently may not perform as well. This is important for key pages that are targeting broader more competitive queries, which may benefit from improved linking and reduced crawl depth. Unimportant pages, pages that target less competitive queries, or pages on large websites will often naturally sit deeper without issue. Most importantly, consider the user, which pages are important for them to navigate to, and their journey to reach the page.",Review pages that are deeper in the website with a high crawl depth. Improve website structure and internal linking to key pages that may benefit where appropriate.,default_config.seospiderconfig,Internal:All
Links with no anchor text,Notices,"Links, Crawlability","This issue is triggered if a link (either external or internal) on your website has an empty or naked anchor (i.e., anchor that uses a raw URL), or anchor text only contains symbols. Although a missing anchor doesn't prevent users and crawlers from following a link, it makes it difficult to understand what the page you're linking to is about. Also, Google considers anchor text when indexing a page. So, a missing anchor represents a lost opportunity to optimize the performance of the linked-to page in search results.","Use anchor text for your links where it is necessary. The link text must give users and search engines at least a basic idea of what the target page is about. Also, use short but descriptive text. For more information, please see the ""Use link wisely"" section in Google's SEO Starter Guide.",Links: Internal Outlinks With No Anchor Text,Opportunity,Low,"Pages that have internal links without anchor text or images that are hyperlinked without alt text. Anchor text is the visible text and words used in hyperlinks that provide users and search engines context about the content of the target page. Internal outlinks without anchor text can be seen in the 'Outlinks' tab, with the 'All Link Types' filter set to 'Hyperlinks', where the 'Anchor Text' column is blank, or if an image, the 'Alt Text' column is also blank. Export in bulk via 'Bulk Export > Links > Internal Outlinks With No Anchor Text'.",Review the missing anchor text outlinks and where appropriate include useful and descriptive anchor text to help users and search engines.,default_config.seospiderconfig,Internal:All
Links with non-descriptive anchor text,Notices,"Links, Indexability","This issue is triggered if a non-descriptive anchor text is used for a link (either internal or external). An anchor is considered to be non-descriptive if it doesn’t give any idea of what the linked-to page is about, for example, “click here”, “right here”, etc. This type of anchor provides little value to users and search engines as it doesn't provide any information about the target page. Also, such anchors will offer little in terms of the target page’s ability to be indexed by search engines, and as a result, rank for relevant search requests. For more information on the criteria used to trigger this check, refer to “What are unoptimized anchors and how does Site Audit identify them?”.","To let users and search engines understand the meaning of the linked-to page, use a succinct anchor text that describes the page’s content. For best practices on how to optimize your anchor text, refer to the “Write good link text” section in Google’s Search Engine Optimization (SEO) Starter Guide.",Links: Non-Descriptive Anchor Text In Internal Outlinks,Opportunity,Low,"Pages that have internal outlinks with anchor text that is not descriptive, such as 'click here' or 'learn more' based upon the preferences under 'Config > Spider > Preferences'. Anchor text is the visible text and words used in hyperlinks that provide users and search engines context about the content of the target page. Internal outlinks with non-descriptive anchor text can be seen in the 'Outlinks' tab, with the 'All Link Types' filter set to 'Hyperlinks', where the 'Anchor Text' column has words such as 'click here', or 'learn more'. Export in bulk via 'Bulk Export > Links > Non-Descriptive Anchor Text In Internal Outlinks'.",Review the non-descriptive anchor text in outlinks and where appropriate update them to include useful and descriptive anchor text to help provide context to both users and search engines.,default_config.seospiderconfig,Internal:All
Broken internal links,Error,"HTTP Status, Links, Crawlability","Broken internal links lead users from one website to another and bring them to non-existent webpages. Multiple broken links negatively affect user experience and may worsen your search engine rankings because crawlers may think that your website is poorly maintained or coded.
Please note that our crawler may detect a working link as broken. Generally, this happens if the server hosting the website you're referring to blocks our crawler from accessing this website.","Please follow all links reported as broken. If a target webpage returns an error, remove the link leading to the error page or replace it with another resource.
If the links reported as broken do work when accessed with a browser, you should contact the website's owner and inform them about the issue.",NA,NA,NA,NA,NA,default_config.seospiderconfig,Internal:All
Malformed links,Error,"Links, Crawlability","This issue is reported when SiteAuditBot fails to crawl a link because of an invalid link's URL.
Common mistakes include the following:
- Invalid URL syntax (e.g., no or an invalid protocol is specified, backslashes (\) are used)
- Spelling mistakes
- Unnecessary additional characters",Make sure the link's URL conforms to a standard scheme and doesn't have any unnecessary characters or typos.,NA,NA,NA,NA,NA,default_config.seospiderconfig,Internal:All
Broken external links,Warnings,"HTTP Status, Links, Crawlability","Broken external links lead users from one website to another and bring them to non-existent webpages. Multiple broken links negatively affect user experience and may worsen your search engine rankings because crawlers may think that your website is poorly maintained or coded.
Please note that our crawler may detect a working link as broken. Generally, this happens if the server hosting the website you're referring to blocks our crawler from accessing this website.","Please follow all links reported as broken. If a target webpage returns an error, remove the link leading to the error page or replace it with another resource.
If the links reported as broken do work when accessed with a browser, you should contact the website's owner and inform them about the issue.",NA,NA,NA,NA,NA,default_config.seospiderconfig,Internal:All
Warning - Too long URLs,Warnings,"Links, Crawlability","This issue is triggered if your link URL is longer than 2,000 characters. Although theoretically there is no character limit for your URLs, it is still recommended that you keep their length under 2,000 characters. This is important because some browsers cannot handle URLs exceeding this limit. Moreover, keeping URLs at a reasonable length will make their crawling much easier, while extremely long URLs may be ignored by search engines.","Try to keep your link URLs shorter than 2,000 characters. For more information, please see this article.",NA,NA,NA,NA,NA,default_config.seospiderconfig,Internal:All
Pages with only one internal link,Notices,"Links, Crawlability","Having very few incoming internal links means very few visits, or even none, and fewer chances of placing in search results. It is a good practice to add more incoming internal links to pages with useful content. That way, you can rest assured that users and search engines will never miss them.",Add more incoming internal links to pages with important content.,NA,NA,NA,NA,NA,default_config.seospiderconfig,Internal:All
Nofollow attributes in external links,Notices,Crawlability,"A nofollow attribute is an element in an <a> tag that tells crawlers not to follow the link. ""Nofollow"" links don’t pass any link juice or anchor texts to referred webpages. The unintentional use of nofollow attributes may have a negative impact on the crawling process and your rankings.","Make sure you haven’t used nofollow attributes by mistake. Remove them from <a> tags, if needed. For more information, please see this Google article.",NA,NA,NA,NA,NA,default_config.seospiderconfig,Internal:All
Nofollow attributes in internal links,Warnings,"Links, Crawlability","The rel=""nofollow"" attribute is an element in an <a> tag that tells crawlers not to follow the link (e.g., ""<a href=""http://example.com/link"" rel=""nofollow"">Nofollow link example</a>"").""Nofollow"" links don’t pass any link juice to referred webpages. That’s why it is not recommended that you use nofollow attributes in internal links. You should let link juice flow freely throughout your website. Moreover, unintentional use of nofollow attributes may result in your webpage being ignored by search engine crawlers even if it contains a valuable content.","Make sure not to use nofollow attributes by mistake. Remove them from <a> tags, if necessary.",NA,NA,NA,NA,NA,default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Meta Description: Multiple,Issue,Medium,Pages which have multiple meta descriptions. There should only be a single meta description for each page. Multiple meta descriptions are often caused by multiple conflicting plugins or modules in CMS.,"Remove the additional meta description tags from the pages HTML, ensuring the website has a single, concise and descriptive meta description for important pages.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Meta Description: Outside <head>,Issue,Medium,"Pages with a meta description that is outside of the <head> element in the HTML. The meta description should be within the <head> element, or search engines may ignore it.",Ensure meta descriptions are in the <head> element of a page's HTML so that search engines can choose to use them for their search engine result page snippets.,default_config.seospiderconfig,Internal:All
Missing meta description,Warnings,"Meta tags, Indexability","Though meta descriptions don't have a direct influence on rankings, they are used by search engines to display your page's description in search results. A good description helps users know what your page is about and encourages them to click on it. If your page's meta description tag is missing, search engines will usually display its first sentence, which may be irrelevant and unappealing to users.
For more information, please see these articles: Create good titles and snippets in Search Results and On-Page SEO Basics: Meta Descriptions","In order to gain a higher click-through rate, you should ensure that all of your webpages have meta descriptions that contain relevant keywords.",Meta Description: Missing,Opportunity,Low,"Pages which have a missing meta description, the content is empty or has a whitespace. This is a missed opportunity to communicate the benefits of your product or service and influence click through rates for important URLs.","It's important to write unique and descriptive meta descriptions on key pages to communicate the purpose of the page to users, and entice them to click on your result over the competition. It can also mean Google use this description for snippets in the search results for some queries, rather than make up their own based upon the content of the page.",default_config.seospiderconfig,Internal:All
Duplicate meta descriptions,Error,"Meta tags, Duplicates, Indexability","Our crawler reports pages that have duplicate meta descriptions only if they are exact matches.
A <meta description> tag is a short summary of a webpage's content that helps search engines understand what the page is about and can be shown to users in search results.
Duplicate meta descriptions on different pages mean a lost opportunity to use more relevant keywords. Also, duplicate meta descriptions make it difficult for search engines and users to differentiate between different webpages. It is better to have no meta description at all than to have a duplicate one.","Provide a unique, relevant meta description for each of your webpages.
Follow the On-Page SEO Basics: Meta Descriptions article - https://www.semrush.com/blog/on-page-seo-basics-meta-descriptions/",Meta Description: Duplicate,Opportunity,Low,"Pages which have duplicate meta descriptions. It's really important to have distinct and unique meta descriptions that communicate the benefits and purpose of each page. If they are duplicate or irrelevant, then they will be ignored by search engines in their snippets.","Update duplicate meta descriptions as necessary, so important pages contain a unique and descriptive title for users and search engines. If these are duplicate pages, then fix the duplicated pages by linking to a single version, and redirect or use canonicals where appropriate.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Meta Description: Below 400 Pixels,Opportunity,Low,"Pages which have meta descriptions much shorter than Google's estimated pixel length limit. This isn't necessarily an issue, but it does indicate there might be room to communicate benefits, USPs or call to actions.","Consider updating the meta description to take advantage of the space left to include additional benefits, USPs or call to actions to improve click through rates (CTR).",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Meta Description: Below 70 Characters,Opportunity,Low,"Pages which have meta descriptions below the configured limit. This isn't strictly an issue, but an opportunity. There is additional room to communicate benefits, USPs or call to actions.","Consider updating the meta description to take advantage of the space left to include additional benefits, USPs or call to actions to improve click through rates (CTR).",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Meta Description: Over 985 Pixels,Opportunity,Low,"Pages which have meta descriptions over Google's estimated pixel length limit for snippets. Google snippet length is actually based upon pixels limits, rather than a character length. The SEO Spider tries to match the latest pixel truncation points in the SERPs, but it is an approximation and Google adjusts them frequently.","Write concise meta descriptions to ensure important words are not truncated in the search results, and not visible to users.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Meta Description: Over 155 Characters,Opportunity,Low,Pages which have meta descriptions over the configured limit. Characters over this limit might be truncated in Google's search results.,"Write concise meta descriptions to ensure important words are not truncated in the search results, and not visible to users.",default_config.seospiderconfig,Internal:All
Title tag is missing or empty,Error,"Meta tags, Indexability","A <title> tag is a key on-page SEO element. It appears in browsers and search results, and helps both search engines and users understand what your page is about.
If a page is missing a title, or a <title> tag is empty, Google may consider it low quality. In case you promote this page in search results, you will miss chances to rank high and gain a higher click-through rate.",Ensure that every page on your website has a unique and concise title containing your most important keywords.,Page Titles: Missing,Issue,High,"Pages which have a missing page title element, the content is empty, or has a whitespace.

Page titles are read and used by both users and the search engines to understand what a page is about.

They are important for SEO as page titles are used in rankings, and vital for user experience, as they are displayed in browsers, search engine results and on social networks.","It’s essential to write concise, descriptive and unique page titles on every indexable URL to help users, and enable search engines to score and rank the page for relevant search queries.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Page Titles: Multiple,Issue,High,Pages which have multiple page titles. There should only be a single page title element for each page. Multiple page titles are often caused by multiple conflicting plugins or modules in CMS.,"Remove the additional <title> tags from the pages HTML, ensuring the website has a single, concise and descriptive page title.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Page Titles: Outside <head>,Issue,High,"Pages with a <title> element that is outside of the <head> element in the HTML. The page <title> should be within the <head> element, or search engines may ignore it. Google will often still recognise the page title even outside of the <head> element, however this should not be relied upon.","Ensure the page <title> element is in the <head> element of a page's HTML so that browsers can use it at the top of their window, and search engines can use it in scoring.",default_config.seospiderconfig,Internal:All
Duplicate title tag,Error,"Meta tags, Duplicates, Indexability","Our crawler reports pages that have duplicate title tags only if they are exact matches.
Duplicate <title> tags make it difficult for search engines to determine which of a website's pages is relevant for a specific search query, and which one should be prioritized in search results. Pages with duplicate titles have a lower chance of ranking well and are at risk of being banned.
Moreover, identical <title> tags confuse users as to which webpage they should follow.",Provide a unique and concise title for each of your pages that contains your most important keywords.,Page Titles: Duplicate,Opportunity,Medium,"Pages which have duplicate page titles. It's really important to have distinct and unique page titles for every page. If every page has the same page title, then it can make it more challenging for users and the search engines to understand one page from another.","Update duplicate page titles as necessary, so each page contains a unique and descriptive title for users and search engines. If these are duplicate pages, then fix the duplicated pages by linking to a single version, and redirect or use canonicals where appropriate.",default_config.seospiderconfig,Internal:All
Title element is too long,Warnings,"Meta tags, Indexability",Most search engines truncate titles containing more than 70 characters. Incomplete and shortened titles look unappealing to users and won't entice them to click on your page.,Try to rewrite your page titles to be 70 characters or less.,Page Titles: Over 60 Characters,Opportunity,Medium,Pages which have page titles that exceed the configured limit. Characters over this limit might be truncated in Google's search results and carry less weight in scoring.,"Write concise page titles to ensure important words are not truncated in the search results, not visible to users and potentially weighted less in scoring.",default_config.seospiderconfig,Internal:All
Title element is too long,Warnings,"Meta tags, Indexability",Most search engines truncate titles containing more than 70 characters. Incomplete and shortened titles look unappealing to users and won't entice them to click on your page.,Try to rewrite your page titles to be 70 characters or less.,Page Titles: Over 561 Pixels,Opportunity,Medium,"Pages which have page titles over Google's estimated pixel length limit for titles in search results. Google snippet length is actually based upon pixels limits, rather than a character length. The SEO Spider tries to match the latest pixel truncation points in the SERPs, but it is an approximation and Google adjusts them frequently.","Write concise page titles to ensure important words are not truncated in the search results, not visible to users and potentially weighted less in scoring.",default_config.seospiderconfig,Internal:All
Title element is too short,Warnings,"Meta tags, Indexability","Generally, using short titles on webpages is a recommended practice. However, keep in mind that titles containing 10 characters or less do not provide enough information about what your webpage is about and limit your page's potential to show up in search results for different keywords.",Add more descriptive text inside your page's <title> tag.,Page Titles: Below 200 Pixels,Opportunity,Medium,"Pages which have page titles much shorter than Google's estimated pixel length limit. This isn't necessarily an issue, but it does indicate there might be room to target additional keywords or communicate your USPs.",Consider updating the page title to take advantage of the space left to include additional target keywords or USPs.,default_config.seospiderconfig,Internal:All
Title element is too short,Warnings,"Meta tags, Indexability","Generally, using short titles on webpages is a recommended practice. However, keep in mind that titles containing 10 characters or less do not provide enough information about what your webpage is about and limit your page's potential to show up in search results for different keywords.",Add more descriptive text inside your page's <title> tag.,Page Titles: Below 30 Characters,Opportunity,Medium,"Pages which have page titles under the configured limit. This isn't necessarily an issue, but it does indicate there might be room to target additional keywords or communicate your USPs.",Consider updating the page title to take advantage of the space left to include additional target keywords or USPs.,default_config.seospiderconfig,Internal:All
Duplicate content in h1 and title,Warnings,"Meta tags, Duplicates, Indexability","It is a bad idea to duplicate your title tag content in your first-level header. If your page's <title> and <h1> tags match, the latter may appear over-optimized to search engines.
Also, using the same content in titles and headers means a lost opportunity to incorporate other relevant keywords for your page.",Try to create different content for your <title> and <h1> tags.,Page Titles: Same as H1,Opportunity,Low,"Page titles which match the h1 on the page exactly. This is not necessarily an issue, but may point to a potential opportunity to target alternative keywords, synonyms, or related key phrases.","This is not necessarily an issue, but may point to a potential opportunity to target alternative keywords, synonyms, or related key phrases.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Response Codes: Internal No Response,Issue,High,"Internal URLs with no response returned from the server. Usually due to a malformed URL, connection timeout, connection error, or connection refused. View URLs that link to no responses using the lower 'inlinks' tab and export them in bulk via 'Bulk Export > Response Codes > Internal > No Response inlinks'.","Malformed URLs should be updated to the correct location and other connection issues can often be resolved by using different user-agents ('Config > User-Agent'), adjusting the crawl speed ('Config > Speed') or disabling firewalls & proxies.",default_config.seospiderconfig,Internal:All
4xx errors,Error,"HTTP Status, Crawlability","A 4xx error means that a webpage cannot be accessed. This is usually the result of broken links. These errors prevent users and search engine robots from accessing your webpages, and can negatively affect both user experience and search engine crawlability. This will in turn lead to a drop in traffic driven to your website. Please be aware that crawler may detect a working link as broken if your website blocks our crawler from accessing it. This usually happens due to the following reasons:
- DDoS protection system
- Overloaded or misconfigured server","If a webpage returns an error, remove all links leading to the error page or replace it with another resource.
To identify all pages on your website that contain links to a 4xx page, click ""View broken links"" next to the error page.
If the links reported as 4xx do work when accessed with a browser, you can try either of the following:
- Contact your web hosting support team
- Instruct search engine robots not to crawl your website too frequently by specifying the ""crawl-delay"" directive in your robots.txt",Response Codes: Internal Client Error (4xx),Issue,High,"Internal URLs with a client-side error. This indicates a problem occurred with the URL request and can include responses such as 400 bad request, 403 Forbidden, 404 Page Not Found, 410 Removed, 429 Too Many Requests and more. A 404 'Page Not Found' is the most common, and often referred to as a broken link. View URLs that link to errors using the lower 'inlinks' tab and export them in bulk via 'Bulk Export > Response Codes > Internal > Client Error (4xx) inlinks'.","All links on a website should ideally resolve to 200 'OK' URLs. Errors such as a 404 or 410 should be updated to their correct locations, removed and redirected where appropriate. A 403 forbidden error occurs when a web server denies access to the SEO Spider's request and can often be resolved by switching the user-agent to Chrome via 'Config > User-Agent' and crawling again.",default_config.seospiderconfig,Internal:All
5xx errors,Error,"HTTP Status, Crawlability","5xx errors refer to problems with a server being unable to perform the request from a user or a crawler. They prevent users and search engine robots from accessing your webpages, and can negatively affect user experience and search engines' crawlability. This will in turn lead to a drop in traffic driven to your website.",Investigate the causes of these errors and fix them.,Response Codes: Internal Server Error (5xx),Issue,High,"Internal URLs where the server failed to fulfill an apparently valid request. This can include common responses such as 500 Internal Server Errors, and 503 Service Unavailable. View URLs that link to errors using the lower 'inlinks' tab and export them in bulk via 'Bulk Export > Response Codes > Internal > Server Error (5xx) inlinks'.","All URLs should respond with a 200 'OK' status and this might indicate a server that struggles under load, or a misconfiguration that requires investigation. Check 500 internal server errors exist in a browser and fix any valid issues. For 503 errors, lower the crawl speed ('Config > Speed') to reduce load on the server and retry URLs via right click 'Re-Spider'.",default_config.seospiderconfig,Internal:All
Redirect chains and loops,Error,"HTTP Status, Crawlability","Redirecting one URL to another is appropriate in many situations. However, if redirects are done incorrectly, it can lead to disastrous results. Two common examples of improper redirect usage are redirect chains and loops.

Long redirect chains and infinite loops lead to a number of problems that can damage your SEO efforts. They make it difficult for search engines to crawl your site, which affects your crawl budget usage and how well your webpages are indexed, slows down your site's load speed, and, as a result, may have a negative impact on your rankings and user experience.

Please note that if you can’t spot a redirect chain with your browser, but it is reported in your Site Audit report, your website probably responds to crawlers’ and browsers’ requests differently, and you still need to fix the issue.","The best way to avoid any issues is to follow one general rule: do not use more than three redirects in a chain.

If you are already experiencing issues with long redirect chains or loops, we recommend that you redirect each URL in the chain to your final destination page.

We do not recommend that you simply remove redirects for intermediate pages as there can be other links pointing to your removed URLs, and, as a result, you may end up with 404 errors.",Response Codes: Internal Redirect Loop,Error,High,"Internal URLs that redirect to another URL, which also then redirects. This can occur multiple times in a row, each redirect is referred to as a ‘hop’.","Ideally all internal links would be to canonical resolving URLs, and avoid linking to URLs that redirect.

Any URL that redirects should reference the final destination, rather than taking multiple ‘hops’ to get there to reduce latency for users, and enhanced efficiency for search engines.

This final URL should ideally resolve to a 200 ‘OK’ status.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Response Codes: Internal Blocked by Robots.txt,Warnings,High,Internal URLs blocked by the site's robots.txt. This means they cannot be crawled and is a critical issue if you want the page content to be crawled and indexed by search engines. View URLs that link to URLs blocked by robots.txt using the lower 'inlinks' tab and export them in bulk via 'Bulk Export > Response Codes > Internal > Blocked by Robots.txt inlinks'.,"Review URLs to ensure they should be disallowed. If they are incorrectly disallowed, then the site's robots.txt should be updated to allow them to be crawled. Consider whether you should be linking internally to these URLs and remove links where appropriate.",default_config.seospiderconfig,Internal:All
Redirect chains and loops,Error,"HTTP Status, Crawlability","Redirecting one URL to another is appropriate in many situations. However, if redirects are done incorrectly, it can lead to disastrous results. Two common examples of improper redirect usage are redirect chains and loops.

Long redirect chains and infinite loops lead to a number of problems that can damage your SEO efforts. They make it difficult for search engines to crawl your site, which affects your crawl budget usage and how well your webpages are indexed, slows down your site's load speed, and, as a result, may have a negative impact on your rankings and user experience.

Please note that if you can’t spot a redirect chain with your browser, but it is reported in your Site Audit report, your website probably responds to crawlers’ and browsers’ requests differently, and you still need to fix the issue.","The best way to avoid any issues is to follow one general rule: do not use more than three redirects in a chain.

If you are already experiencing issues with long redirect chains or loops, we recommend that you redirect each URL in the chain to your final destination page.

We do not recommend that you simply remove redirects for intermediate pages as there can be other links pointing to your removed URLs, and, as a result, you may end up with 404 errors.",Response Codes: Internal Redirect Chain,Warnings,Medium,"Internal URLs that redirect to another URL, which also then redirects. This can occur multiple times in a row, each redirect is referred to as a 'hop'. Full redirect chains can be viewed and exported via 'Reports > Redirects > Redirect Chains'.","Ideally all internal links would be to canonical resolving URLs, and avoid linking to URLs that redirect. Any URL that redirects should reference the final destination, rather than taking multiple 'hops' to get there to reduce latency for users, and enhanced efficiency for search engines. This final URL should ideally resolve to a 200 'OK' status.",default_config.seospiderconfig,Internal:All
Disallowed internal resources,Warnings,Crawlability,"Blocked resources are resources (e.g., CSS, JavaScript, image files, etc.) that are blocked from crawling by a ""Disallow"" directive in your robots.txt file. By disallowing these files, you're preventing search engines from accessing them and, as a result, properly rendering and indexing your webpages. This, in return, may lead to lower rankings.","To unblock a resource, simply update your robots.txt file.",Response Codes: Internal Blocked Resource,Warnings,High,"Internal resources (such as images, JavaScript and CSS) that are blocked from rendering by robots.txt or an error. This filter will only populate when JavaScript rendering is enabled (blocked resources will appear under 'Blocked by Robots.txt' in default 'text only' crawl mode). This can be an issue as the search engines might not be able to access critical resources to be able to render pages accurately. Blocked resources can be viewed by URL in the 'Rendered Page' tab, and any pages with blocked resources can be viewed under 'JavaScript > Pages with Blocked Resources'.",Update the robots.txt and resolve any errors to allow all critical resources to be crawled and used for rendering of website content.,default_config.seospiderconfig,Internal:All
Disallowed external resources,Notices,Crawlability,"Blocked external resources are resources (e.g., CSS, JavaScript, image files, etc.) that are hosted on an external website and blocked from crawling by a ""Disallow"" directive in an external robots.txt file. Disallowing these files may prevent search engines from accessing them and, as a result, properly rendering and indexing your webpages. This, in return, may lead to lower rankings. ","If blocked resources that are hosted on an external website have a strong impact on your website, contact the website owner and ask them to edit their robots.txt file.
If blocked resources are not necessary for your site, simply ignore them.",Response Codes: External Blocked Resource,Warnings,Medium,"External resources (such as images, JavaScript and CSS) that are blocked from rendering by robots.txt or an error.

This can be an issue as the search engines might not be able to access critical resources to be able to render pages accurately.","If critical to your content, update the external subdomains robots.txt and resolve any errors to allow resources to be crawled and used for rendering of the websites content.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Response Codes: Internal Redirection (3xx),Warnings,Low,"Internal URLs which redirect to another URL. These will include server-side redirects, such as 301 or 302 redirects (and more). View URLs that link to redirects using the lower 'inlinks' tab and export them in bulk via 'Bulk Export > Response Codes > Internal > Redirection (3xx) inlinks'.","Ideally all internal links would be to canonical resolving URLs, and avoid linking to URLs that redirect. This reduces latency of redirect hops for users, and enhanced efficiency for search engines.",default_config.seospiderconfig,Internal:All
Meta refresh redirects,Error,Crawlability,"A meta refresh tag instructs a web browser to redirect a user to a different page after a given interval. Generally, it is recommended that you avoid using a meta refresh tag as it is considered a poor, slow and outdated technique that may lead to SEO and usability issues.","Review all pages with a meta refresh tag. If this tag is used to redirect an old page to a new one, replace it with a 301 redirect.",Response Codes: Internal Redirection (Meta Refresh),Warnings,Low,Internal URLs with a meta refresh. This is a client-side redirect which instructs the browser to ‘refresh’ to a URL with a specific time.,"Ideally server-side redirects should be used for redirection and all internal links would be to canonical resolving URLs, and avoid linking to URLs that redirect.

This reduces latency of redirect hops for users, and enhanced efficiency for search engines.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Response Codes: Internal Redirection (JavaScript),Warnings,Low,Internal URLs with a JavaScript redirect to another URL.,"Ideally all internal links would be to canonical resolving URLs, and avoid linking to URLs that redirect.

This reduces latency of redirect hops for users, and enhanced efficiency for search engines.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Response Codes: External No Response,Warnings,Low,"External URLs with no response returned from the server. Usually due to a malformed URL, connection timeout, connection error, or connection refused.","Malformed URLs often respond with ‘DNS Lookup Failed’ and won’t resolve at all in a browser. They should be updated to the correct location.

Other connection issues should be checked in a browser, as they might be due to security identifying the SEO Spider request as a bot. They can often be ignored or resolved by using different user-agents (‘Config > User-Agent’), adjusting the crawl speed (‘Config > Speed’), disabling firewalls & proxies or adding your IP address to security platform allowlists.
",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Response Codes: External Client Error (4XX),Warnings,Low,"External URLs with a client-side error.

This indicates a problem occurred with the URL request and can include responses such as 400 bad request, 403 Forbidden, 404 Page Not Found, 410 Removed, 429 Too Many Requests and more.

A 404 ‘Page Not Found’ is the most common, and often referred to as a broken link.","All links on a website should ideally resolve to 200 ‘OK’ URLs.

Errors such as 404 broken links should be updated so users are taken to the correct URL, or removed.

A 403 forbidden error is also common on the web today and occurs when a web server denies access to the SEO Spider’s request. This isn’t usually an issue for users if accessible in a browser, and can be ignored.

A 403 error can often be resolved by switching the user-agent to Chrome via ‘Config > User-Agent’ and crawling again.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Response Codes: External Server Error (5XX),Warnings,Low,External URLs where the server failed to fulfill an apparently valid request. This can include common responses such as 500 Internal Server Errors and 503 Service Unavailable.,"All external URLs should ideally respond with a 200 ‘OK’ status for users. A 5XX response might indicate a server that struggles under load, or a misconfiguration that leads to an error page.

If they can be viewed in a browser, then it’s often not an issue. If they error in a browser, then considering updating the external link as appropriate.",default_config.seospiderconfig,Internal:All
Permanent redirects,Notices,"HTTP Status, Crawlability","Although using permanent redirects (a 301 or 308 redirect) is appropriate in many situations (for example, when you move a website to a new domain, redirect users from a deleted page to a new one, or handle duplicate content issues), we recommend that you keep them to a reasonable minimum. Every time you redirect one of your website's pages, it decreases your crawl budget, which may run out before search engines can crawl the page you want to be indexed. Moreover, too many permanent redirects can be confusing to users.",Review all URLs with a permanent redirect. Change permanent redirects to a target page URL where possible.,NA,NA,NA,NA,NA,default_config.seospiderconfig,Internal:All
Temporary redirects,Warnings,"HTTP Status, Crawlability","Temporary redirects (i.e., a 302 and a 307 redirect) mean that a page has been temporarily moved to a new location. Search engines will continue to index the redirected page, and no link juice or traffic is passed to the new page, which is why temporary redirects can damage your search rankings if used by mistake.","Review all URLs to make sure the use of 302 and 307 redirects is justified. If so, don’t forget to remove them when they are no longer needed. However, if you permanently move any page, replace a 302/307 redirect with a 301/308 one.",NA,NA,NA,NA,NA,default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Security: HTTP URLs,Issue,High,"HTTP URLs that are encountered in the crawl. All websites should be secure over HTTPS today on the web. Not only is it important for security, but it's now expected by users. Chrome and other browsers display a 'Not Secure' message against any URLs that are HTTP, or have mixed content issues (where they load insecure resources on them). To view how these URLs were discovered, view their 'inlinks' in the lower window tab. You can also export any pages that link to HTTP URLs via 'Bulk Export > Security > HTTP URLs Inlinks'.","All URLs should be to secure HTTPS pages. Pages should be served over HTTPS, any internal links should be updated to HTTPS versions and HTTP URLs should 301 redirect to HTTPS versions. HTTP URLs identified in this filter that are redirecting to HTTPS versions already should be updated to link to the correct HTTPS versions directly.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Security: Mixed Content,Issue,High,"HTML pages loaded over a secure HTTPS connection that have resources such as images, JavaScript or CSS that are loaded via an insecure HTTP connection.

Mixed content weakens HTTPS, and makes the pages easier for eavesdropping and compromising otherwise secure pages.

Browsers might automatically block the HTTP resources from loading, or they may attempt to upgrade them to HTTPS.","All HTTP resources should be changed to HTTPS to avoid security issues, and problems loading in a browser.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Security: Form URL Insecure,Issue,High,"HTML pages that contain a form with an action attribute URL that is insecure (HTTP).

This means that any data entered into the form is not secure, as it could be viewed in transit.",All URLs contained within forms across a website should be encrypted and therefore need to be HTTPS.,default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Security: Form On HTTP URL,Issue,High,"This indicates that a form is on an HTTP page. Any data entered into the form, including usernames and passwords is not secure.","All HTTP pages with forms should be changed to HTTPS to avoid security issues for users, and problems loading in a browser.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Security: Missing HSTS Header,Warnings,Low,"URLs that are missing the HSTS response header. The HTTP Strict-Transport-Security response header (HSTS) instructs browsers that it should only be accessed using HTTPS, rather than HTTP. If a website accepts a connection to HTTP, before being redirected to HTTPS, visitors will initially still communicate over HTTP. The HSTS header instructs the browser to never load over HTTP and to automatically convert all requests to HTTPS.","The HSTS header should be used across all pages to instruct the browser that it should always request pages via HTTPS, rather than HTTP.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Security: Unsafe Cross-Origin Links,Warnings,Low,"URLs that link to external websites using the target=""_blank"" attribute (to open in a new tab), without using rel=""noopener"" (or rel=""noreferrer"") at the same time. Using target=""_blank"" alone leaves those pages exposed to both security and performance issues for some legacy browsers, which are estimated to be below 5% of market share. Setting target=""_blank"" on <a> elements implicitly provides the same rel behavior as setting rel=""noopener"" which does not set window.opener for most modern browsers, such as Chrome, Safari, Firefox and Edge. The external links that contain the target=""_blank"" attribute by itself can be viewed in the 'outlinks' tab and 'target' column. They can be exported alongside the pages they are linked from via 'Bulk Export > Security > Unsafe Cross-Origin Links'.","Consider the benefits of including the rel=""noopener"" link attribute on any links that contain the target=""_blank"" attribute to avoid security and performance issues for the users of legacy browsers that may visit the website.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Security: Protocol-Relative Resource Links,Warnings,Low,"URLs that load resources such as images, JavaScript and CSS using protocol-relative links. A protocol-relative link is simply a link to a URL without specifying the scheme (for example, //screamingfrog.co.uk). It helps save developers time from having to specify the protocol and lets the browser determine it based upon the current connection to the resource. However, this technique is now an anti-pattern with HTTPS everywhere, and can expose some sites to 'man in the middle' compromises and performance issues",Update any resource links to be absolute links including the scheme (HTTPS) to avoid security and performance issues.,default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Security: Missing Content-Security-Policy Header,Warnings,Low,"URLs that are missing the Content-Security-Policy response header. This header allows a website to control which resources are loaded for a page. This policy can help guard against cross-site scripting (XSS) attacks that exploit the browser's trust of the content received from the server. The SEO Spider only checks for existence of the header, and does not interrogate the policies found within the header to determine whether they are well set-up for the website. This should be performed manually.",Set a strict Content-Security-Policy response header across all page to help mitigate cross site scripting (XSS) and data injection attacks.,default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Security: Missing X-Content-Type-Options Header,Warnings,Low,"URLs that are missing the 'X-Content-Type-Options' response header with a 'nosniff' value. In the absence of a MIME type, browsers may 'sniff' to guess the content type to interpret it correctly for users. However, this can be exploited by attackers who can try and load malicious code, such as JavaScript via an image they have compromised.","To minimise security issues, the X-Content-Type-Options response header should be supplied and set to 'nosniff'. This instructs browsers to rely only on the Content-Type header and block anything that does not match accurately. This also means the content-type set needs to be accurate.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Security: Missing X-Frame-Options Header,Warnings,Low,"URLs missing an X-Frame-Options response header with a 'DENY' or 'SAMEORIGIN' value. This instructs the browser not to render a page within a frame, iframe, embed or object. This helps avoid 'clickjacking' attacks, where your content is displayed on another web page that is controlled by an attacker.","To minimise security issues, the X-Frame-Options response header should be supplied with a 'DENY' or 'SAMEORIGIN' value.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Security: Missing Secure Referrer-Policy Header,Warnings,Low,"URLs missing 'no-referrer-when-downgrade', 'strict-origin-when-cross-origin', 'no-referrer' or 'strict-origin' policies in the Referrer-Policy header. When using HTTPS, it's important that the URLs do not leak in non-HTTPS requests. This can expose users to 'man in the middle' attacks, as anyone on the network can view them.","Consider setting a referrer policy of strict-origin-when-cross-origin. It retains much of the referrer's usefulness, while mitigating the risk of leaking data cross-origins.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Security: Bad Content Type,Warnings,Low,"This indicates any URLs where the actual content type does not match the content type set in the header. It also identifies any invalid MIME types used. When the X-Content-Type-Options: nosniff response header is set by the server this is particularly important, as browsers rely on the content type header to correctly process the page. This can cause HTML web pages to be downloaded instead of being rendered when they are served with a MIME type other than text/html for example.","Analyse URLs identified with a bad content type, and set an accurate MIME type in the content-type header.",default_config.seospiderconfig,Internal:All
HTTPS encryption not used,Warnings,Security and HTTPS,"Google considers a website's security as a ranking factor. Websites that do not support HTTPS connections may be less prominent in Google's search results, while HTTPS-protected sites will rank higher with its search algorithms.",Switch your site to HTTPS.,NA,NA,NA,NA,NA,default_config.seospiderconfig,Internal:All
Non-secure pages,Error,Security and HTTPS,"This issue is triggered if our crawler detects an HTTP page with a <input type=""password""> field.
Using a <input type=""password""> field on your HTTP page is harmful to user security, as there is a high risk that user login credentials can be stolen. To protect users' sensitive information from being compromised, Google Chrome will start informing users about the dangers of submitting their passwords on HTTP pages by labeling such pages as ""non-secure"" starting January 2017. This could have a negative impact on your bounce rate, as users will most likely feel uncomfortable and leave your page as quickly as possible.",Move your HTTP webpages that contain a password field to HTTPS.,NA,NA,NA,NA,NA,default_config.seospiderconfig,Internal:All
issues with expiring or expired certificate,Error,Security and HTTPS,"This issue is triggered if your certificate has expired or will expire soon.
If you allow your certificate to expire, users accessing your website will be presented with a Warnings message, which usually stops them from going further and may lead to a drop in your organic search traffic.",Ask your website administrator to renew the certificate and run periodic checks to avoid any future issues.,NA,NA,NA,NA,NA,default_config.seospiderconfig,Internal:All
Old security protocol version,Error,Security and HTTPS,"Running SSL or old TLS protocol (version 1.0) is a security risk, which is why it is strongly recommended that you implement the newest protocol versions.",Update your security protocol to the latest version.,NA,NA,NA,NA,NA,default_config.seospiderconfig,Internal:All
Certificate registered to incorrect name,Error,Security and HTTPS,"If the domain or subdomain name to which your SSL certificate is registered doesn't match the name displayed in the address bar, web browsers will block users from visiting your website by showing them a name mismatch error, and this will in turn negatively affect your organic search traffic.","Contact your website administrator and ask them to install the correct certificate.
Since subdomains also require their own certificates, you can use a wildcard or multi-domain SSL certificate that allows you to secure multiple subdomains.",NA,NA,NA,NA,NA,default_config.seospiderconfig,Internal:All
Issues with mixed content,Error,Security and HTTPS,"If your website contains any elements that are not secured with HTTPS, this may lead to security issues. Moreover, browsers will warn users about loading unsecure content, and this may negatively affect user experience and reduce their confidence in your website.","Only embed HTTPS content on HTTPS pages.
Replace all HTTP links with the new HTTPS versions. If there are any external links leading to a page that has no HTTPS version, remove those links.",NA,NA,NA,NA,NA,default_config.seospiderconfig,Internal:All
Insecure encryption algorithms,Error,Security and HTTPS,"This issue is triggered when we connect to your web server and detect that it uses old or deprecated encryption algorithms. Using outdated encryption algorithms is a security risk that can have a negative impact on your user experience and search traffic. Some web browsers may warn users accessing your website about loading insecure content. This usually negatively affects their confidence in your website, thereby stopping them from going further, and as a result you may experience a drop in your organic search traffic.",Contact your website administrator and ask them to update encryption algorithms.,NA,NA,NA,NA,NA,default_config.seospiderconfig,Internal:All
Links lead to HTTP pages for HTTPS site,Warnings,"Links, Security and HTTPS","If any link on website points to the old HTTP version of website, search engines can become confused as to which version of the page they should rank.",Replace all HTTP links with the new HTTPS versions.,NA,NA,NA,NA,NA,default_config.seospiderconfig,Internal:All
No SNI support,Warnings,Security and HTTPS,"One of the common issues you may face when using HTTPS is when your web server doesn't support Server Name Indication (SNI). Using SNI allows you to support multiple servers and host multiple certificates at the same IP address, which may improve security and trust.","Make sure that you web server supports SNI. Keep in mind that SNI is not supported by some older browsers, which is why you need to ensure that your audience uses browsers supporting SNI.",NA,NA,NA,NA,NA,default_config.seospiderconfig,Internal:All
No HSTS support,Notices,Security and HTTPS,"HTTP Strict Transport Security (HSTS) informs web browsers that they can communicate with servers only through HTTPS connections. So, to ensure that you don't serve unsecured content to your audience, we recommend that you implement HSTS support.",Use a server that supports HSTS.,NA,NA,NA,NA,NA,default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,URL: Multiple Slashes,Issue,Low,URLs that have multiple forward slashes in the path (example.com/page1//). This is generally by mistake and as best practice URLs should only have a single slash between sections of a path to avoid any potential mix ups and duplicate URLs within the string. This is excluding use within the protocol (https://).,"Ideally only a single slash should be used for URLs. However, changing URLs is a big decision, and often it's not worth changing them for SEO purposes alone. If URLs are changed, then appropriate 301 redirects must be implemented.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,URL: Contains A Space,Issue,Low,URLs that contain a space. These are considered unsafe and could cause the link to be broken when sharing the URL. Hyphens should be used as word separators instead of spaces.,"Ideally hyphens should be used as word separators, rather than spaces. However, changing URLs is a big decision.

If URLs are changed, then appropriate 301 redirects must be implemented.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,URL: Broken Bookmark,Issue,Low,"URLs that have a broken bookmark (also known as ‘named anchors’, ‘jump links’, and ‘skip links’) that link users to a specific part of a webpage using an ID attribute in the HTML and append a fragment (#) and the ID name to the URL.

When the link is clicked, the page will scroll to the location with the bookmark.

While these links can be excellent for users, it’s easy to make mistakes in the set-up, and they often become ‘broken’ over time as pages are updated and IDs are changed or removed.

A broken bookmark will mean the user is still taken to the correct page, but they won’t be directed to the intended section.

While Google will see these URLs as the same page (as it ignores anything from the #), they can use named anchors for ‘jump to’ links in their search results for the page ranking.",Review the pages that link to the broken bookmarks by using the ‘Inlinks’ tab and ensure this has the correct ID attribute that’s used on the page for the relevant section.,default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,URL: Non ASCII Characters,Warnings,Low,URLs with characters outside of the ASCII character-set. Standards outline that URLs can only be sent using the ASCII character-set and some users may have difficulty with subtleties of characters outside this range.,"URLs should be converted into a valid ASCII format, by encoding links to the URL with safe characters (made up of % followed by two hexadecimal digits). Today browsers and the search engines are largely able to transform URLs accurately.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,URL: Uppercase,Warnings,Low,"URLs that have uppercase characters within them. URLs are case sensitive, so as best practice generally URLs should be lowercase, to avoid any potential mix ups and duplicate URLs.","Ideally lowercase characters should be used for URLs only. However, changing URLs is a big decision, and often it's not worth changing them for SEO purposes alone. If URLs are changed, then appropriate 301 redirects must be implemented.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,URL: Repetitive Path,Warnings,Low,"URLs that have repetitive paths or subfolders within the string (example.com/page1/page/page1/page2). In some cases this can be legitimate and logical, however it also often points to poor URL structure and potential improvements. It can also help identify issues with incorrect relative linking, causing infinite URLs.","While not always an issue repetitive paths aren't particularly user friendly, or could be causing crawling issues if due to incorrect relative linking. Ideally any URL should be as concise as possible. However, changing URLs is a big decision, and often it's not worth changing them for SEO purposes alone. If URLs are changed, then appropriate 301 redirects must be implemented.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,URL: Internal Search,Warnings,Low,URLs that might be part of the websites internal search function. Google and other search engines recommend blocking internal search pages from being crawled to limit sometimes duplicate and low quality pages from being crawled and indexed.,"Most internal site searches are built for users, rather than search engines who may needlessly crawl and index them. As best practise most search sections of a site should not be linked to internally, and should be disallowed in robots.txt.",default_config.seospiderconfig,Internal:All
Too many URL parameters,Warnings,Crawlability,Using too many URL parameters is not an SEO-friendly approach. Multiple parameters make URLs less enticing for users to click and may cause search engines to fail to index some of your most important pages.,Try to use no more than three parameters in your URLs.,URL: Parameters,Warnings,Low,"URLs that include parameters such as '?' or '&'. This isn't an issue for Google or other search engines to crawl unless at significant scale, but it's recommended to limit the number of parameters in a URL which can be complicated for users, and can be a sign of low value-add URLs.","Where possible use a static URL structure without parameters for key indexable URLs. However, changing URLs is a big decision, and often it's not worth changing them for SEO purposes alone. If URLs are changed, then appropriate 301 redirects must be implemented.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,URL: GA Tracking Parameters,Warnings,Low,"URLs that contain Google Analytics tracking parameters. In addition to creating duplicate pages that must be crawled, using tracking parameters on links internally can overwrite the original session data. utm= parameters strip the original source of traffic and starts a new session with the specified attributes. _ga= and _gl= parameters are used for cross-domain linking and identify a specific user, including this on links prevents a unique user ID from being assigned.","Remove the tracking parameters from links. Event Tracking is recommended in place of utm parameters for tracking additional interactions on a page such as downloads, link clicks, form submissions, and video plays.",default_config.seospiderconfig,Internal:All
Underscores in URL,Warnings,"Links, Crawlability","When it comes to URL structure, using underscores as word separators is not recommended because search engines may not interpret them correctly and may consider them to be a part of a word. Using hyphens instead of underscores makes it easier for search engines to understand what your page is about.
Although using underscores doesn't have a huge impact on webpage visibility, it decreases your page's chances of appearing in search results, as opposed to when hyphens are used.","Replace underscores with hyphens. However, if your page ranks well, we do not recommend that you do this.",URL: Underscores,Opportunity,Low,"URLs with underscores, which are not always seen as word separators by search engines.","Ideally hyphens should be used as word separators, rather than underscores. However, changing URLs is a big decision, and often it's not worth changing them for SEO purposes alone. If URLs are changed, then appropriate 301 redirects must be implemented.",default_config.seospiderconfig,Internal:All
Too long URLs,Notices,"Links, Crawlability","According to Google, long URLs are not SEO friendly. Excessive URL length intimidates users and discourages them from clicking or sharing it, thus hurting your page's click-through rate and usability.",Keep your URLs at a reasonable length.,URL: Over 115 Characters,Opportunity,Low,"URLs that are more than the configured length. This is generally not an issue, however research has shown that users prefer shorter, concise URL strings.","Where possible use logical and concise URLs for users and search engines. However, changing URLs is a big decision, and often it's not worth changing them for SEO purposes alone. If URLs are changed, then appropriate 301 redirects must be implemented.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Validation: Missing <head> Tag,Issue,High,"Pages missing a <head> element within the HTML.

The <head> element is a container for metadata about the page, that’s placed between the <html> and <body> tag.

Metadata is used to define the page title, character set, styles, scripts, viewport and other data that’s critical to the page.

Browsers and Googlebot will automatically generate a <head> element if it’s omitted in the markup, however it may not contain meaningful metadata for the page and this should not be relied upon.",Ensure all pages have a valid <head> element with appropriate metadata for the document that is the first element in the <html> element,default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Validation: Multiple <head> Tags,Issue,High,"Pages with multiple <head> elements in the HTML. There should only be one <head> element in the HTML which contains all critical metadata for the document. Browsers and Googlebot will combine metadata from subsequent <head> elements if they are both before the <body>, however this should not be relied upon and is open to potential mix-ups. Any <head> tags after the <body> starts will be ignored.",Ensure all pages have a single valid <head> element with appropriate metadata for the document that is the first element in the <html> element.,default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Validation: Missing <body> Tag,Issue,High,"Pages missing a <body> element within the HTML. The <body> element contains all the content of a page, including links, headings, paragraphs, images and more. There should be one <body> element in the HTML of the page. Browsers and Googlebot will automatically generate a <body> element if it's omitted in the markup, however this should not be relied upon.",Ensure all pages have a single valid <body> element with appropriate content for the document.,default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Validation: Multiple <body> Tags,Issue,High,"Pages with multiple <body> elements in the HTML. There should only be one <body> element in the HTML which contains all content for the document. Browsers and Googlebot will try to combine content from subsequent <body> elements, however this should not be relied upon and is open to potential mix ups.",Ensure all pages have a single valid <body> element with appropriate content for the document.,default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Validation: HTML Document Over 15mb,Issue,High,"Pages which are over 15mb in document size. This is important as Googlebot limit their crawling and indexing to the first 15MB of an HTML file or supported text-based file.

This size does not include resources referenced in the HTML such as images, videos, CSS, and JavaScript that are fetched separately.

Google only considers the first 15MB of the file for indexing and stops crawling afterwards. The file size limit is applied on the uncompressed data.

The median size of a HTML file is about 30 kilobytes (kB), so pages are highly unlikely to reach this limit.","Ensure all pages are below 15mb in file size. Identify why the page is so ridiculously large, and consider any necessary improvements, such as moving inline CSS and scripts to external files or breaking up the page where appropriate.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Validation: Resource Over 15mb,Issue,High,"JavaScript and CSS files which are over 15mb in size. This is important as Googlebot limit their crawling and indexing to the first 15MB of a file.

This means anything beyond this limit in JavaScript or CSS might not be processed.

Google only considers the first 15MB of the file for indexing and stops crawling afterwards. The file size limit is applied on the uncompressed data.","Ensure all resources are below 15mb in file size.

Identify why the resource is so large, and consider any necessary improvements to reduce file size where appropriate.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Validation: Invalid HTML Elements In <head>,Warnings,High,"Pages with invalid HTML elements within the <head>. When an invalid element is used in the <head>, Google assumes the end of the <head> element and ignores any elements that appear after the invalid element. This means critical <head> elements that appear after the invalid element will not be seen. The <head> element as per the HTML standard is reserved for title, meta, link, script, style, base, noscript and template elements only.","Ensure the <head> element only uses valid elements as per HTML specifications to ensure critical tags are seen by search engines. Common invalid elements include <img> and <iframe> elements. Google strongly recommend against including them in the <head>, but if you must, place these invalid elements after the ones you want Google to see.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Validation: <body> Element Preceding <html>,Warnings,High,"Pages that have a body element (such as a <div>, <p> or <img> etc) preceding the opening <html> element.

Browsers and Googlebot will automatically assume the start of the <body> and generate an empty <head> element before it. This means the intended <head> element below and its metadata will be seen in the <body> and ignored.",Ensure <body> elements do not precede the <html> element and they are only in the <body> element.,default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Validation: <head> Not First In <html> Element,Warnings,High,"Pages with an HTML element that proceed the <head> element in the HTML. The <head> should be the first element in the <html> element.

Browsers and Googlebot will automatically generate a <head> element if it’s not first in the HTML.

While ideally <head> elements would be in the <head>, if a valid <head> element is first in the <html> it will be considered as part of the generated <head>.

However, if non <head> elements such as <p>, <body>, <img> etc are used before the intended <head> element and its metadata, then Google assumes the end of the <head> element.

This means the intended <head> element and its metadata will be seen in the <body> and ignored.",Ensure all pages have a valid <head> element with appropriate metadata for the document that is the first element in the <html> element.,default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Validation: High Carbon Rating,Opportunity,Low,"Pages that have a carbon rating of F using the digital carbon ratings system from Sustainable Web Design.

This scale equates page weight tracked by the HTTP Archive with CO2 estimates per page view. The CO2 calculation uses the ‘The Sustainable Web Design Model’ for calculating emissions, which considers datacentres, network transfer and device usage in calculations.

The CO2 calculation and rating system can be used as a benchmark, as well as a catalyst to contribute to a more sustainable web.","Consider optimisation opportunities to reduce file size and CO2 emissions, and improve carbon footprint and rating.

The CO2 calculation and carbon rating can be integrated with analytics data to help prioritise which areas or URLs should be focused upon.

Review best practices and opportunities listed under the PageSpeed tab for more specific actions.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,AMP: Non-200 Response,Issue,High,"AMP URLs which do not respond with a 200 ‘OK’ status code.

These will include URLs blocked by robots.txt, no responses, redirects, client and server errors.","Ensure AMP URLs are accessible, that they can be crawled and respond with a 200 status code for both users and search engines.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,AMP: Missing Non-AMP Return Link,Issue,High,"AMP URLs that have a canonical non-AMP version that does not contain a rel=""amphtml"" URL back to the AMP URL. This could simply be missing from the non-AMP version, or there might be a configuration issue with the AMP canonical.","Ensure canonical and non-AMP versions of URLs contain a rel=""amphtml"" link to the AMP version so they are discoverable and confirm the relationship.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,AMP: Missing Canonical to Non-AMP,Issue,High,"AMP URLs with a canonical that does not go to a non-AMP version, but to another AMP URL.","Ensure AMP canonical URLs correctly go to non-AMP equivalents, rather than to another AMP URL.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,AMP: Non-Indexable Canonical,Issue,High,The AMP canonical URL is a non-indexable page. The non-AMP equivalent set as the canonical URL of the AMP should be an indexable page.,Update AMP canonical URLs so they correctly go to canonical and indexable non-AMP equivalents.,default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,AMP: Missing <html amp> Tag,Issue,High,AMP HTML documents must contain a top-level HTML or HTML AMP tag.,Review the AMP HTML specification and update the AMP to meet the guidelines.,default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,AMP: Missing/Invalid Doctype HTML Tag,Issue,High,"AMP HTML documents must start with the doctype, doctype HTML.",Review the AMP HTML specification and update the AMP to meet the guidelines.,default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,AMP: Missing Head Tag,Issue,High,AMP HTML documents must contain head tags (they are optional in HTML).,Review the AMP HTML specification and update the AMP to meet the guidelines.,default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,AMP: Missing Body Tag,Issue,High,AMP HTML documents must contain body tags (they are optional in HTML).,Review the AMP HTML specification and update the AMP to meet the guidelines.,default_config.seospiderconfig,Internal:All
Missing canonical tags in AMP pages,Error,"Indexability, Mobile SEO, Canonicalization","This issue is triggered if your AMP page has no canonical tag.
When creating AMP pages, several requirements should be met:
- If you have both an AMP and a non-AMP version of the same page, you should place canonical tags on both versions to prevent duplicate content issues
- If you have only an AMP version of your webpage, it must have a self-referential canonical tag","Add a rel=""canonical"" tag in the <head> section of each AMP page.",AMP: Missing Canonical,Issue,High,"AMP URLs must contain a canonical tag inside their head that points to the regular HTML version of the AMP HTML document, or to itself if no such HTML version exists.",Review the AMP HTML specification and update the AMP to meet the guidelines.,default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,AMP: Missing/Invalid Meta Charset Tag,Issue,High,AMP HTML documents must contain a <meta charset=”UTF-8″> tag as the first child of their head tag.,Review the AMP HTML specification and update the AMP to meet the guidelines.,default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,AMP: Missing/Invalid Meta Viewport Tag,Issue,High,"AMP HTML documents must contain a:

<meta name=""viewport"" content=”width=device-width,minimum-scale=1″>

Tag inside their head tag. It’s also recommended to include initial-scale=1.",Review the AMP HTML specification and update the AMP to meet the guidelines.,default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,AMP: Missing/Invalid AMP Script,Issue,High,"AMP HTML documents must contain a:

<script async src=""https://cdn.ampproject.org/v0/amp-script-0.1.js""></script>

Tag inside their head tag.",Review the AMP HTML specification and update the AMP to meet the guidelines.,default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,AMP: Missing/Invalid AMP Boilerplate,Issue,High,AMP HTML documents must contain the AMP boilerplate code in their head tag.,Review the AMP HTML specification and update the AMP to meet the guidelines.,default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,AMP: Contains Disallowed HTML,Issue,High,AMP URLs with disallowed HTML for AMP according to the official AMP validator (https://validator.ampproject.org/).,Validate the AMP using the official AMP validator and remove or resolve any disallowed HTML issues identified.,default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,AMP: Other Validation Errors,Issue,High,AMP URLs with validation errors for AMP using the official AMP validator (https://validator.ampproject.org/).,Validate the AMP using the official AMP validator and resolve any validation errors identified.,default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,AMP: Indexable,Warnings,High,"The AMP URL is indexable. AMP URLs with a non-AMP equivalent should be non-indexable (as they should have a canonical to the non-AMP equivalent).

Standalone AMP URLs (without an equivalent) should be indexable.","Analyse indexable AMP URLs identified to verify they are standalone pages. AMP URLs with a non-AMP equivalent should be non-indexable, with a canonical to the non-AMP version.",default_config.seospiderconfig,Internal:All
AMP Pages with HTML Issues,Error,"Indexability, Mobile SEO","In order for AMP pages to be served properly to mobile users, they must be compliant with AMP guidelines.
If your HTML doesn't adhere to AMP standards, your AMP page will not work correctly and may not be indexed by search engines, and, as a result, may not appear in mobile search results.","Since there are multiple reasons why your page's HTML may not comply with AMP standards, we provide specific how-to-fix tips for each invalid AMP page. These tips are provided in the 'Issue Description' column on the page that lists all pages with HTML issues.",NA,NA,NA,NA,NA,default_config.seospiderconfig,Internal:All
AMP Pages with Style and Layout Issues,Error,"Indexability, Mobile SEO","In order for AMP pages to be served properly to mobile users, they must be compliant with AMP guidelines.
If the style and layout of your AMP page do not adhere to AMP standards, the page will not work correctly and may not be indexed by search engines, and, as a result, may not appear in mobile search results.","Since there are multiple reasons why your page's style and layout may not comply with AMP standards, we provide specific how-to-fix tips for each invalid AMP page. These tips are provided in the 'Issue Description' column on the page that lists all pages with style and layout issues.",NA,NA,NA,NA,NA,default_config.seospiderconfig,Internal:All
AMP Pages with Templating Issues,Error,"Indexability, Mobile SEO","In order for AMP pages to be served properly to mobile users, they must be compliant with AMP guidelines.
If your AMP page includes templating syntax, it will not work correctly and may not be indexed by search engines, and, as a result, may not appear in mobile search results.","Since there are different types of templating issues that your AMP page can have, we provide specific how-to-fix tips for each invalid AMP page. These tips are provided in the 'Issue Description' column on the page that lists all pages with templating issues.",NA,NA,NA,NA,NA,default_config.seospiderconfig,Internal:All
Duplicate content,Error,"Duplicates, Indexability","Webpages are considered duplicates if their content is 85% identical.
Having duplicate content may significantly affect your SEO performance.
First of all, Google will typically show only one duplicate page, filtering other instances out of its index and search results, and this page may not be the one you want to rank.
In some cases, search engines may consider duplicate pages as an attempt to manipulate search engine rankings and, as a result, your website may be downgraded or even banned from search results.
Moreover, duplicate pages may dilute your link profile.","Here are a few ways to fix duplicate content issues:
- Add a rel=""canonical"" link to one of your duplicate pages to inform search engines which page to show in search results
- Use a 301 redirect from a duplicate page to the original one
- Use a rel=""next"" and a rel=""prev"" link attribute to fix pagination duplicates
- Instruct GoogleBot to handle URL parameters differently using Google Search Console
- Provide some unique content on the webpage",Content: Exact Duplicates,Issue,High,"Pages that are identical to each other using the MD5 algorithm which calculates a ‘hash’ value for each page and can be seen in the ‘hash’ column.

This check is performed against the full HTML of the page. It will show all pages with matching hash values that are exactly the same.

Exact duplicate pages can lead to the splitting of PageRank signals, crawling inefficiencies and unpredictability in ranking.","There should only be a single canonical version of a URL that exists and is linked to internally. Other versions should not be linked to, and they should be 301 redirected to the canonical version.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Content: Spelling Errors,Issue,Medium,"Pages which contain spelling errors. Spelling, punctuation and grammar issues are a poor experience for users.

While this does not affect SEO directly, Google’s own search quality evaluator guidelines outline spelling and grammar errors numerous times as one of the characteristics of low-quality pages.",Correct any spelling errors on the page to improve user experience and ensure the search engines can understand and rank your content accurately.,default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Content: Grammar Errors,Issue,Medium,"Pages which contain grammar errors. Grammar, punctuation and spelling issues are a poor experience for users.

While this does not affect SEO directly, Google’s own search quality evaluator guidelines outline spelling and grammar errors numerous times as one of the characteristics of low-quality pages.",Correct any grammar errors on the page to improve user experience and ensure the search engines can understand and rank your content accurately.,default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Content: Soft 404 Pages,Warnings,High,"Pages that respond with a '200' status code suggesting they are 'OK', but appear to be an error page - often referred to as a '404' or 'page not found'. These typically should respond with a 404 status code if the page is no longer available. These pages are identified by looking for common error text used on pages, such as 'Page Not Found', or '404 Page Can't Be Found'. The text used to identify these pages can be configured under 'Config > Spider > Preferences'.","Soft 404 pages should be reviewed and if true error pages should be configured to return a '404' status code. All links on a website should ideally resolve to working pages for users. Links to error pages should be updated to their correct locations, removed and redirected where appropriate.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Content: Lorem Ipsum Placeholder,Warnings,High,"Pages that contain 'Lorem ipsum' text that is commonly used as a placeholder to demonstrate the visual form of a webpage. This can be left on web pages by mistake, particularly during new website builds.","Review pages that contain 'Lorem ipsum' text and ensure any placeholder text is replaced with unique, original and relevant copy for the web page.",default_config.seospiderconfig,Internal:All
Duplicate content,Error,"Duplicates, Indexability","Webpages are considered duplicates if their content is 85% identical.
Having duplicate content may significantly affect your SEO performance.
First of all, Google will typically show only one duplicate page, filtering other instances out of its index and search results, and this page may not be the one you want to rank.
In some cases, search engines may consider duplicate pages as an attempt to manipulate search engine rankings and, as a result, your website may be downgraded or even banned from search results.
Moreover, duplicate pages may dilute your link profile.","Here are a few ways to fix duplicate content issues:
- Add a rel=""canonical"" link to one of your duplicate pages to inform search engines which page to show in search results
- Use a 301 redirect from a duplicate page to the original one
- Use a rel=""next"" and a rel=""prev"" link attribute to fix pagination duplicates
- Instruct GoogleBot to handle URL parameters differently using Google Search Console
- Provide some unique content on the webpage",Content: Near Duplicates,Warnings,Medium,"Pages that are near duplicate in content based upon the configured similarity threshold (set at 90% by default) using the minhash algorithm.

Near duplicate pages can cause cannibalisation issues, crawling and indexing inefficiencies and might be a sign of low quality page content.","Having very similar pages can cause cannibalisation issues and crawling and indexing inefficiencies.

Very similar pages should be minimised and high similarity could be a sign of low-quality pages, which haven’t received much love – or just shouldn’t be separate pages in the first place.

Analyse the near duplicates, considering importance of the page and scale. Then improve content to make more unique if necessary, or consolidate, block, remove, or leave as they are where appropriate.",default_config.seospiderconfig,Internal:All
Low word count,Warnings,Indexability,"This issue is triggered if the number of words on your webpage is less than 200.
The amount of text placed on your webpage is a quality signal to search engines.
Search engines prefer to provide as much information to users as possible, so pages with longer content tend to be placed higher in search results, as opposed to those with lower word counts.",Improve your on-page content and be sure to include more than 200 meaningful words.,Content: Low Content Pages,Opportunity,Medium,"Pages with a word count that is below the default 200 words. The word count is based upon the content area settings used in the analysis which can be configured via 'Config > Content > Area'. There isn't a minimum word count for pages in reality, but the search engines do require descriptive text to understand the purpose of a page. This filter should only be used as a rough guide to help identify pages that might be improved by adding more descriptive content in the context of the website and page's purpose. Some websites, such as ecommerce, will naturally have lower word counts, which can be acceptable if a products details can be communicated efficiently.",Consider including additional descriptive content to help the user and search engines better understand the page.,default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Content: Readability Difficult,Opportunity,Low,"Copy on the page is difficult to read and best understood by college graduates according to the Flesch reading-ease score formula.

Copy that has long sentences and uses complex words are generally harder to read and understand.","Consider improving the readability of copy for your target audience.

Copy that uses shorter sentences with less complex words is often easier to read and understand.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Content: Readability Very Difficult,Opportunity,Low,"Copy on the page is very difficult to read and best understood by university graduates according to the Flesch reading-ease score formula.

Copy that has long sentences and uses complex words are generally harder to read and understand.","Consider improving the readability of copy for your target audience.

Copy that uses shorter sentences with less complex words is often easier to read and understand.",default_config.seospiderconfig,Internal:All
www resolve issues,Error,"Duplicates, Crawlability","Normally, a webpage can be accessed with or without adding www to its domain name. If you haven’t specified which version should be prioritized, search engines will crawl both versions, and the link juice will be split between them. Therefore, none of your page versions will get high positions in search results.",Specify which version of your webpage you want to be the main one. Use Google Search Console data to define pages that are indexed. We recommend that you redirect an alternate version of your page to the preferred version via a 301 redirect.,NA,NA,NA,NA,NA,default_config.seospiderconfig,Internal:All
Large HTML page size,Error,"Crawlability, Site Performance","A webpage’s HTML size is the size of all HTML code contained on it. A page size that is too large (i.e., exceeding 2 MB) leads to a slower page load time, resulting in a poor user experience and a lower search engine ranking.",Review your page’s HTML code and consider optimizing its structure and/or removing inline scripts and styles.,NA,NA,NA,NA,NA,default_config.seospiderconfig,Internal:All
Low text to HTML ratio,Warnings,Indexability,"Your text to HTML ratio indicates the amount of actual text you have on your webpage compared to the amount of code. This issue is triggered when your text to HTML is 10% or less.
Search engines have begun focusing on pages that contain more content. That's why a higher text to HTML ratio means your page has a better chance of getting a good position in search results.
Less code increases your page's load speed and also helps your rankings. It also helps search engine robots crawl your website faster.","Split your webpage's text content and code into separate files and compare their size. If the size of your code file exceeds the size of the text file, review your page's HTML code and consider optimizing its structure and removing embedded scripts and styles.",NA,NA,NA,NA,NA,default_config.seospiderconfig,Internal:All
Viewport not configured,Error,"Crawlability, Mobile SEO",The viewport meta tag is an HTML tag that allows you to control a page's viewport size and scale on mobile devices. This tag is indispensable if you want to make your website accessible and optimized for mobile devices.,"Set the viewport meta tag for each page, and then test your website on a mobile device to make sure everything works fine.",Mobile: Viewport Not Set,Issue,High,"Pages without a viewport meta tag, or a viewport meta tag without a content attribute that includes the text width=.

Setting the viewport meta tag allows the width and scaling to be sized correctly on all devices.

Without this set, mobile devices will render pages at desktop screen widths and scale them down, making the text difficult to read.",Add a viewport meta tag with the appropriate key-value pairs to the <head> of the page so that it’s sized correctly on all devices.,default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Mobile: Content Not Sized Correctly,Issue,High,"Pages with content that is smaller or larger than the viewport width, which means it may not render correctly on mobile devices.

Lighthouse flags pages whose width isn’t equal to the width of the viewport.

Please note: This issue and PWA testing has been deprecated in Lighthouse. While this issue is not available via the PSI 'Remote' API option, it is still available via the PSI 'Local' option, as Screaming Frog has maintained support. This can be configured via 'Config > API Access > PSI'.",Follow best practices for responsive web design to ensure the page is mobile-friendly and will render correctly on mobile screens.,default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Mobile: Illegible Font Size,Issue,High,"Pages with small font sizes that can make it difficult to read for users on mobile devices.

Lighthouse will flag pages that have font sizes smaller than 12px, which make up more than 40% of the page text.",Review font sizes in the CSS and consider increasing them to at least 12 px on at least 60% of the text on the page for improved mobile usability.,default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Mobile: Contains Unsupported Plugins,Issue,High,"Pages with browser plugins such as Flash, Silverlight, or Java Applets that most mobile devices and browsers do not support and search engines cannot index.","Remove old plugin files from pages. For any pages that still rely on any of these plugins, migrate to more modern open web technologies, which are faster, more power-efficient and secure. Consider converting plugin-based content to HTML, such as Flash to HTML5 video.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Mobile: Target Size,Issue,Medium,"Pages with tap targets that are too small or there is not enough space around them, which means they are difficult to interact with on mobile devices.

Tap targets (also known as ‘touch targets’) are buttons, links or form elements that users on touch devices can use.

Insufficient size or spacing can also make it challenging for users with mobility impairments, or anyone experiencing difficulties controlling fine movement.

Tap targets must have sufficient size and spacing in order to “be easily activated without accidentally activating an adjacent target.”

Tap targets must be at least 24 by 24 CSS pixels in size.","Increase the size of tap targets that are too small, or increase the space between the tap targets so they are not so close together using properties like margin.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Mobile: Mobile Alternate Link,Warnings,High,"Pages that contain a rel=”alternate” link element to a mobile version.

While this is an acceptable set up, it means serving different HTML to each device on separate URLs. This can often be less efficient than a responsive design approach.","Consider moving to a responsive web design approach in the future, which is recommended by Google as typically it’s the easiest to implement and maintain.

Ensure the mobile versions of URLs are correctly canonicalised to the desktop equivalents.",default_config.seospiderconfig,Internal:All
Viewport width not set,Error,Mobile SEO,"This issue is triggered if the viewport meta tag used on your page is missing the width or initial-scale value.
The viewport meta tag is an HTML tag that allows you to control a page’s viewport size and scale on mobile devices. This tag is indispensable if you want to make your website accessible and optimized for mobile devices.","Specify the width and initial-scale values. We recommend you contact your developers for assistance. Once this is done, check your page for mobile-friendliness or re-audit your site.",NA,NA,NA,NA,NA,default_config.seospiderconfig,Internal:All
Invalid robots.txt format,Error,Crawlability,"If your robots.txt file is poorly configured, it can cause you a lot of problems.
Webpages that you want to be promoted in search results may not be indexed by search engines, while some of your private content may be exposed to users.
So, one configuration mistake can damage your search rankings, ruining all your search engine optimization efforts.","Review your robots.txt file and fix all errors, if there are any.
You can check your file using Google's robots.txt Tester",NA,NA,NA,NA,NA,default_config.seospiderconfig,Internal:All
Sitemap file too large,Error,Crawlability,"This issue is triggered if the size of your sitemap.xml file (uncompressed) exceeds 50 MB or it contains more than 50,000 URLs. Sitemap files that are too large will put your site at risk of being ineffectively crawled or even ignored by search engines.","Break up your sitemap into smaller files. You will also need to create a sitemap index file to list all your sitemaps and submit it to Google.
Don't forget to specify the location of your new sitemap.xml files in your robots.txt.",Sitemaps: XML Sitemap With Over 50k URLs,Issue,High,"XML Sitemaps that has more than the permitted 50k URLs.

All sitemap formats limit a single sitemap to 50,000 URLs and 50MB (uncompressed) in size.",Break XML Sitemaps into multiple smaller sitemaps within the 50k URL limit. Consider creating a sitemap index file (a file that points to a list of sitemaps) and submit that single index file to Google.,default_config.seospiderconfig,Internal:All
Sitemap file too large,Error,Crawlability,"This issue is triggered if the size of your sitemap.xml file (uncompressed) exceeds 50 MB or it contains more than 50,000 URLs. Sitemap files that are too large will put your site at risk of being ineffectively crawled or even ignored by search engines.","Break up your sitemap into smaller files. You will also need to create a sitemap index file to list all your sitemaps and submit it to Google.
Don't forget to specify the location of your new sitemap.xml files in your robots.txt.",Sitemaps: XML Sitemap Over 50mb,Issue,High,"XML Sitemaps that is larger than the permitted 50mb file size.

All sitemap formats limit a single sitemap to 50MB (uncompressed) and 50,000 URLs.","URLs that are not in an XML Sitemap, but were discovered in the crawl.

This might be on purpose (as they are not important), or they might be missing, and the XML Sitemap needs to be updated to include them.

This filter does not consider non-indexable URLs, it assumes they are correctly non-indexable, and therefore shouldn’t be flagged to be included.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Sitemaps: URLs Not In Sitemap,Issue,Medium,"Break XML Sitemaps into multiple smaller sitemaps within the 50mb size limit.

Consider creating a sitemap index file (a file that points to a list of sitemaps) and submit that single index file to Google.","Consider including important canonical URLs within the XML Sitemap.

This does not make up for good site architecture and internal linking, but it can aid discovery for large websites, inform Google when the page was last updated, and aid with monitoring indexing of pages.",default_config.seospiderconfig,Internal:All
Orphaned sitemap pages,Notices,Crawlability,"An orphaned page is a webpage that is not linked to internally. Including orphaned pages in your sitemap.xml files is considered to be a bad practice, as these pages will be crawled by search engines. Crawling outdated orphaned pages will waste your crawl budget. If an orphaned page in your sitemap.xml file has valuable content, we recommend that you link to it internally.","Review all orphaned pages in your sitemap.xml files and do either of the following:
 - If a page is no longer needed, remove it
 - If a page has valuable content and brings traffic to your website, link to it from another page on your website
 - If a page serves a specific need and requires no internal linking, leave it as is",Sitemaps: Orphan URLs,Issue,Medium,"URLs that are only in an XML Sitemap, but were not discovered during the crawl.

Or, URLs that are only discovered from URLs in the XML Sitemap, but were not found in the crawl.

These might be accidentally included in the XML Sitemap, or they might be pages that you wish to be indexed, and should really be linked to internally.","Review orphan URLs and link to them internally from the website if they should rank in the search results.

Remove any pages from the XML Sitemap that should not be indexed and use appropriate directives such as ‘noindex’.",default_config.seospiderconfig,Internal:All
Incorrect pages found in sitemap.xml,Error,Crawlability,"A sitemap.xml file makes it easier for crawlers to discover the pages on your website. Only good pages intended for your visitors should be included in your sitemap.xml file.
This error is triggered if your sitemap.xml contains URLs that:
- lead to webpages with the same content
- redirect to a different webpage
- return non-200 status code
Populating your file with such URLs will confuse search engines, cause unnecessary crawling or may even result in your sitemap being rejected..","Review your sitemap.xml for any redirected, non-canonical or non-200 URLs. Provide the final destination URLs that are canonical and return a 200 status code.",Sitemaps: Non-Indexable URLs In Sitemap,Issue,Medium,"URLs that are in an XML Sitemap, but are non-indexable, and hence should be removed, or their indexability needs to be fixed.",XML Sitemaps should only include indexable pages. Remove non-indexable URLs from the XML Sitemap or update to the correct canonical versions.,default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Sitemaps: URLs In Multiple Sitemaps,Warnings,Low,"URLs that are in more than one XML Sitemap.

This isn’t necessarily a problem, but generally a URL only needs to be in a single XML Sitemap.",Review URLs that are in multiple XML Sitemaps and remove where appropriate so they are referenced in a single XML Sitemap.,default_config.seospiderconfig,Internal:All
Invalid sitemap.xml format,Error,Crawlability,"If your sitemap.xml file has any errors, search engines will not be able to process the data it contains, and they will ignore it.","Review your sitemap.xml file and fix all errors.
You can check your file using the Sitemaps report in Google Search Console",NA,NA,NA,NA,NA,default_config.seospiderconfig,Internal:All
Sitemap.xml not specified in robots.txt,Warnings,Crawlability,"If you have both a sitemap.xml and a robots.txt file on your website, it is a good practice to place a link to your sitemap.xml in your robots.txt, which will allow search engines to better understand what content they should crawl.","Specify the location of your sitemap.xml in your robots.txt. To check if Googlebot can index your sitemap.xml file, use the Sitemaps report in Google Search Console",NA,NA,NA,NA,NA,default_config.seospiderconfig,Internal:All
Sitemap.xml not found,Warnings,Crawlability,"A sitemap.xml file is used to list all URLs available for crawling. It can also include additional data about each URL.
Using a sitemap.xml file is quite beneficial. Not only does it provide easier navigation and better visibility to search engines, it also quickly informs search engines about any new or updated content on your website. Therefore, your website will be crawled faster and more intelligently.","Consider generating a sitemap.xml file if you don't already have one.
Then you should specify the location of your sitemap.xml files in your robots.txt, and check if Googlebot can index your sitemap.xml file with the Sitemaps report in Google Search Console",NA,NA,NA,NA,NA,default_config.seospiderconfig,Internal:All
HTTP URLs in sitemap.xml for HTTPS site,Warnings,Security and HTTPS,Your sitemap.xml should include the links that you want search engines to find and index. Using different URL versions in your sitemap could be misleading to search engines and may result in an incomplete crawling of your website.,Replace all HTTP URLs in your sitemap.xml with HTTPS URLs.,NA,NA,NA,NA,NA,default_config.seospiderconfig,Internal:All
Structured data that contains markup errors,Error,Crawlability,"This issue is triggered if structured data items contain fields that do not meet Google's guidelines.
Implementing and maintaining your structured data correctly is important if you want to get an edge over your competitors in search results.
If your website markup has errors, crawlers will not be able to properly understand it, and you may run the risk of losing the chance of gaining rich snippets and getting more favorable rankings.","Check structured data on your webpages with a validation tool. Please note that different markup testing tools may show different results.
We recommend that you use the Rich Results Test tool to review and validate your pages’ structured data against their rich snippet requirements.",Structured Data: Validation Errors,Issue,High,"URLs that contain structured data validation errors related to Schema.org.

Schema.org validation includes checks against whether the types and properties exist against main and pending Schema vocabulary and will show ‘errors’ for any issues encountered.","Resolve validation errors to ensure pages have valid structured data and are eligible for special search result features in Google.

Review the ‘Structured Data Details’ tab for more information on specific errors and refer to Schema.org specifications where necessary.

Export unique validation errors using ‘Reports > Structured Data > Validation Errors & Warnings Summary’ and test in the Schema Markup Validator.",default_config.seospiderconfig,Internal:All
Structured data that contains markup errors,Error,Crawlability,"This issue is triggered if structured data items contain fields that do not meet Google's guidelines.
Implementing and maintaining your structured data correctly is important if you want to get an edge over your competitors in search results.
If your website markup has errors, crawlers will not be able to properly understand it, and you may run the risk of losing the chance of gaining rich snippets and getting more favorable rankings.","Check structured data on your webpages with a validation tool. Please note that different markup testing tools may show different results.
We recommend that you use the Rich Results Test tool to review and validate your pages’ structured data against their rich snippet requirements.",Structured Data: Rich Result Validation Errors,Issue,High,URLs that contain Google rich result feature validation errors. Google rich result feature validation will show errors for missing required properties or problems with the implementation of required properties. Google's 'required properties' must be included and be valid for content to be eligible for display as a rich result.,Resolve validation errors to ensure pages are eligible for special search result features in Google. Review the 'Structured Data Details' tab for more information on specific errors and refer to Google rich result feature docs where necessary. Export unique validation errors using 'Reports > Structured Data > Validation Errors & Warnings Summary' and test in Google's Rich Results tool.,default_config.seospiderconfig,Internal:All
Structured data that contains markup errors,Error,Crawlability,"This issue is triggered if structured data items contain fields that do not meet Google's guidelines.
Implementing and maintaining your structured data correctly is important if you want to get an edge over your competitors in search results.
If your website markup has errors, crawlers will not be able to properly understand it, and you may run the risk of losing the chance of gaining rich snippets and getting more favorable rankings.","Check structured data on your webpages with a validation tool. Please note that different markup testing tools may show different results.
We recommend that you use the Rich Results Test tool to review and validate your pages’ structured data against their rich snippet requirements.",Structured Data: Parse Errors,Issue,High,"URLs which have structured data that failed to parse correctly.

This is often due to incorrect mark-up in the structured data, which might impact search engines’ ability to interpret it reliably.","Review and resolve any issues in the structured data markup, so that they can be parsed reliably.

Debug parsing errors using the JSON-LD Playground tool or Schema Markup Validator.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Structured Data: Missing,Opportunity,Low,"URLs that do not contain any structured data. This is a potential opportunity to provide explicit clues about the meaning of pages and enable special search result features and enhancements in Google. Structured data will only be discovered if JSON-LD, microdata and RDFa formats are selected for extraction via 'Config > Spider > Extraction'.",Review pages and consider appropriate types of structured data that provide the search engines with a better understanding of the page and Google's search feature gallery (https://developers.google.com/search/docs/guides/search-gallery) for opportunities to enable special search result features and enhancements.,default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Structured Data: Validation Warnings,Opportunity,Low,"URLs that contain structured data validation Warnings, such as for using older data-vocabulary.org schema rather than the recommended Schema.org.

Data-vocabulary.org markup is no longer eligible for Google rich result features.","Remove older data-vocabulary.org markup and replace with schema.org structured data to be eligible for special rich result search features in Google.

Refer to schema.org and Google rich result documentation where necessary.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Structured Data: Rich Result Validation Warnings,Opportunity,Low,"URLs that contain Google rich result feature validation Warnings. These will always be for 'recommended properties', rather than required properties. Recommended properties can be included to add more information about content which could provide a better user experience, but they do not disqualify you from being eligible for rich snippets.",Consider Warnings as 'opportunities' to improve the data provided to search engines and users to potentially enhance special search result features in Google. Review the 'Structured Data Details' tab for more information on specific Warnings and refer to Google rich result feature docs where necessary. Export unique validation errors using 'Reports > Structured Data > Validation Errors & Warnings Summary'.,default_config.seospiderconfig,Internal:All
Slow page load speed,Error,Site Performance,"Page (HTML) load speed is one of the most important ranking factors. The quicker your page loads, the higher the rankings it can receive. Moreover, fast-loading pages positively affect user experience and may increase your conversion rates.
Please note that ""page load speed"" usually refers to the amount of time it takes for a webpage to be fully rendered by a browser. However, crawler only measures the time it takes to load a webpage’s HTML code - load times for images, JavaScript and CSS are not factored in.","The main factors that negatively affect your HTML page generation time are your server’s performance and the density of your webpage’s HTML code.
So, try to clean up your webpage’s HTML code. If the problem is with your web server, you should think about moving to a better hosting service with more resources.",NA,NA,NA,NA,NA,default_config.seospiderconfig,Internal:All
Issues with incorrect hreflang links,Error,Indexability,"A hreflang (rel=""alternate"" hreflang=""x"") attribute helps search engines understand which page should be shown to visitors based on their location. Utilizing this attribute is necessary if you're running a multilingual website and would like to help users from other countries find your content in the language that is most appropriate for them.
It is very important to make sure your hreflang links always refer to absolute URLs with HTTP 200 status codes, otherwise search engines will not be able to interpret them correctly and, as a result, will not show the correct language version of your pages to the relevant audience.","To avoid any problems with hreflang links, we recommend that you review your hreflang attributes and do the following:
- Fix broken hreflang URLs
- Fix hreflang redirects
- Replace relative URLs with absolute ones",Hreflang: Non-200 Hreflang URLs,Issue,High,"URLs contained within rel=”alternate” hreflang annotations that do not have a 200 response code, such as URLs blocked by robots.txt, no responses, 3XX (redirects), 4XX (client errors) or 5XX (server errors).

Hreflang URLs must be crawlable and indexable and therefore non-200 URLs are treated as errors, and ignored by the search engines.","Ensure URLs within hreflang annotations are to the correct canonical and indexable pages.

If Google can’t see pages pointing to each other due to a non-200 response, the tags will be ignored.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Hreflang: Missing Return Links,Issue,High,"URLs with missing return links (or ‘return tags’ in Google Search Console) to them, from their alternate pages.

Hreflang is reciprocal, so all alternate versions must confirm the relationship. When page X links to page Y using hreflang to specify it as its alternate page, page Y must have a return link.

No return links means the hreflang annotations may be ignored or not interpreted correctly.",Ensure alternate pages include hreflang annotations to URLs which are missing return links. This will confirm they are a ‘set’ of alternate pages.,default_config.seospiderconfig,Internal:All
Hreflang language mismatch issues,Notices,Indexability,"This issue is triggered if a language value specified in a hreflang attribute doesn't match your page's language, which is determined based on semantic analysis.
Any mistakes in hreflang attributes may confuse search engines, and your hreflang attributes will most likely be interpreted incorrectly. So it's worth taking the time to make sure you don't have any issues with hreflang attributes.","Review all pages reported to have this issue and fix all hreflang attributes.
Please note that our crawler may report your webpage to have a ""hreflang language mismatch"" issue even if the hreflang value shows the correct language. This usually happens if your webpage is multilingual or has too little content.",Hreflang: Inconsistent Language & Region Confirmation Links,Issue,High,URLs with inconsistent language and regional return links to them. This is where a return link has a different language or regional value than the URL is referencing itself.,Ensure alternate pages include the same language and regional values in its hreflang annotation return links as the page declares within its own.,default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Hreflang: Non-Canonical Return Links,Issue,High,"URLs with non-canonical hreflang return links.

Hreflang should only include canonical versions of URLs and this filter picks up return links that go to URLs that are not the canonical version set by the page.",Update hreflang annotations to include canonical versions of URLs only. They should not include links which are canonicalised to other URLs.,default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Hreflang: Noindex Returns Links,Issue,High,"URLs with return links which have a ‘noindex’ meta tag.

All pages within a set should be indexable, and hence any return URLs with ‘noindex’ may result in the hreflang relationship being ignored.",Update hreflang annotations to include indexable URLs only. They should not include links which are ‘noindex’.,default_config.seospiderconfig,Internal:All
Issues with hreflang values,Error,Indexability,"This issue is triggered if:
- Your country code is not in the ISO_3166-1_alpha-2 format
- Your language code is not in the ISO 639-1 format

A hreflang (rel=""alternate"" hreflang=""x"") attribute helps search engines understand which page should be shown to visitors based on their location. Utilizing this attribute is necessary if you're running a multilingual website and would like to help users from other countries find your content in the language that is most appropriate to them.
It is very important to properly implement hreflang attributes, otherwise search engines will not be able to show the correct language version of your page to the relevant audience.","Make sure that your hreflang attributes are used correctly. Here are a few ways to avoid hreflang implementation issues:
- Specify the correct ISO 639-1 language code. For language script variations, use the ISO 15924 standard format
- Specify the correct ISO_3166-1_alpha-2 country code",Hreflang: Incorrect Language & Region Codes,Issue,High,URLs with hreflang annotations that contain invalid language (in ISO 639-1 format) and or optional regional (in ISO 3166-1 Alpha 2 format) values.,"Update hreflang annotations to include valid language and regional values, so they can be used for geotargeting the right audiences appropriately.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Hreflang: Multiple Entries,Issue,High,"URLs with multiple entries to a language or regional code.

For example, if page X links to page Y and Z using the same ‘en’ hreflang value annotation.

This filter will also pick up multiple implementations, for example, if hreflang annotations were discovered as link elements and via HTTP header.

While multiple implementations are permitted by Google, there’s no benefit and it can increase the likelihood of implementation error.","Update hreflang annotations to only use a language and region pair once, so they can be used for geotargeting the right audiences appropriately. If you have multiple implementations, consider using one preferred implementation.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Hreflang: Not Using Canonical,Issue,High,URLs not using the canonical URL on the page in its own hreflang annotation. Hreflang should only include canonical versions of URLs.,Update hreflang annotations to include canonical versions of URLs only. They should not include links which are canonicalised to other URLs.,default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Hreflang: Outside <head>,Issue,High,"Pages with an hreflang link element that is outside of the <head> element in the HTML.

The hreflang link element should be within the <head> element, or search engines will ignore it.",Ensure hreflang link elements are in the <head> element of a page’s HTML to be used by search engines.,default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Hreflang: Unlinked Hreflang URLs,Issue,Medium,"URLs that are only discoverable via rel=”alternate” hreflang link annotations.

Hreflang annotations do not pass PageRank like a traditional anchor tag, so this might be a sign of a problem with internal linking, or the URLs contained in the hreflang annotation.

It can also mean the crawl hasn’t been set up to crawl all pages.","Ensure URLs within hreflang annotations are linked to using <a> tags, so they can be crawled, indexed and ranking by search engines.",default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Hreflang: Missing Self Reference,Warnings,Low,"URLs missing their own self referencing rel=”alternate” hreflang annotation.

It was previously a requirement to have a self-referencing hreflang, but Google has updated their guidelines to say this is optional.

It is however good practice and often easier to include a self referencing attribute.",Consider adding a self referencing rel=”alternate” hreflang annotation as Google still describe this as best practice in their documentation.,default_config.seospiderconfig,Internal:All
NA,NA,NA,NA,NA,Hreflang: Missing X-Default,Warnings,Low,"URLs missing an x-default hreflang attribute. This is optional, and not necessarily an issue.","Consider adding a fallback page for unmatched languages, especially on language/country selectors or auto-redirecting homepages.",default_config.seospiderconfig,Internal:All
Hreflang conflicts within page source code,Error,Indexability,"If you're running a multilingual website, it is necessary to help users from other countries find your content in the language that is most appropriate for them. This is where the hreflang (rel=""alternate"" hreflang=""x"") attribute comes in handy. This attribute helps search engines understand which page should be shown to visitors based on their location. It is very important to properly synchronize your hreflang attributes within your page's source code, otherwise you may experience unexpected search engine behavior. ","To avoid any conflicts, we recommend that you review your hreflang attributes within your page's source code and fix any of the following issues:
- Conflicting hreflang and rel=canonical URLs
- Conflicting hreflang URLs
- No self-referencing hreflang URLs",NA,NA,NA,NA,NA,default_config.seospiderconfig,Internal:All
Missing hreflang and lang attributes,Warnings,Indexability,"This issue is reported if your page has neither lang nor hreflang attribute.
When running a multilingual website, you should make sure that you’re doing it correctly.
First, you should use a hreflang attribute to indicate to Google which pages should be shown to visitors based on their location. That way, you can rest assured that your users will always land on the correct language version of your website.
You should also declare a language for your webpage’s content (i.e., lang attribute). Otherwise, your web text might not be recognized by search engines. It also may not appear in search results, or may be displayed incorrectly.","Perform the following:
- Add a lang attribute to the <html> tag, e.g., ""<html lang=""en"">""
- Add a hreflang attribute to your page's <head> tag, e.g., <link rel=""alternate"" href=""http://example.com/"" hreflang=""en""/>",NA,NA,NA,NA,NA,default_config.seospiderconfig,Internal:All
Pages not crawled,Error,"HTTP Status, Crawlability","This issue indicates that our crawler couldn't access the webpage. There are two possible reasons:
- Your site's server response time is more than 5 seconds
- Your server refused access to your webpages",Please contact your web hosting technical support team and ask them to fix the issue.,NA,NA,NA,NA,NA,default_config.seospiderconfig,Internal:All
DNS resolution issue,Error,Crawlability,A DNS resolution error is reported when our crawler can't resolve the hostname when trying to access your webpage.,Please contact your web hosting technical support and ask them to investigate and fix the issue.,NA,NA,NA,NA,NA,default_config.seospiderconfig,Internal:All
We couldn't open the page?s URL,Error,Crawlability,"This issue is reported when crawler fails to access a page because of an invalid page URL. Common mistakes include the following:
- Invalid URL syntax (e.g., no or an invalid protocol is specified, backslashes () are used).
- Spelling mistakes.
- Unnecessary additional characters.",Make sure your page's URL conforms to a standard scheme and doesn't have any unnecessary characters or typos.,NA,NA,NA,NA,NA,default_config.seospiderconfig,Internal:All
Blocked from crawling,Notices,Crawlability,"If a page cannot be accessed by search engines, it will never appear in search results. A page can be blocked from crawling either by a robots.txt file or a noindex meta tag.",Make sure that pages with valuable content are not blocked from crawling by mistake.,NA,NA,NA,NA,NA,default_config.seospiderconfig,Internal:All
Robots.txt not found,Notices,Crawlability,"A robots.txt file has an important impact on your overall SEO website's performance. This file helps search engines determine what content on your website they should crawl.
Utilizing a robots.txt file can cut the time search engine robots spend crawling and indexing your website.","If you don't want specific content on your website to be crawled, creating a robots.txt file is recommended. To check your robots.txt file, use Google's robots.txt Tester in Google Search Console",NA,NA,NA,NA,NA,default_config.seospiderconfig,Internal:All
Blocked by X-Robots-Tag: noindex HTTP header,Notices,Crawlability,"The x-robots-tag is an HTTP header that can be used to instruct search engines whether or not they can index or crawl a webpage. This tag supports the same directives as a regular meta robots tag and is typically used to control the crawling of non-HTML files. If a page is blocked from crawling with x-robots-tag, it will never appear in search results.",Make sure that pages with valuable content are not blocked from crawling by mistake.,NA,NA,NA,NA,NA,default_config.seospiderconfig,Internal:All
Encoding not declared,Warnings,Crawlability,"Providing a character encoding tells web browsers which set of characters must be used to display a webpage’s content. If a character encoding is not specified, browsers may not render the page content properly, which may result in a negative user experience. Moreover, search engines may consider pages without a character encoding to be of little help to users and, therefore, place them lower in search results than those with a specified encoding.","Declare a character encoding either by specifying one in the charset parameter of the HTTP Content-Type header (Content-Type: text/html; charset=utf-8) or by using a meta charset attribute in your webpage HTML (<meta charset=""utf-8""/>).",NA,NA,NA,NA,NA,default_config.seospiderconfig,Internal:All
Doctype not declared,Warnings,Crawlability,"A webpage’s doctype instructs web browsers which version of HTML or XHTML is being used. Declaring a doctype is extremely important in order for a page’s content to load properly. If no doctype is specified, this may lead to various problems, such as messed up page content or slow page load speed, and, as a result, negatively affect user experience.","Specify a doctype for each of your pages by adding a <!Doctype> element (e.g., ""<!Doctype html>"") to the very top of every webpage source, right before the <html> tag.",NA,NA,NA,NA,NA,default_config.seospiderconfig,Internal:All
Incompatible plugins used,Warnings,"Indexability, Mobile SEO","This issue is triggered if your page has content based on Flash, JavaApplet, or Silverlight plugins.
These types of plugins do not work properly on mobile devices, which frustrates users.
Moreover, they cannot be crawled and indexed properly, negatively impacting your website’s mobile rankings.",Convert unsupported plugin content into HTML5. ,NA,NA,NA,NA,NA,default_config.seospiderconfig,Internal:All
Frames used,Warnings,Indexability,"<frame> tags are considered to be one of the most significant search engine optimization issues. Not only is it difficult for search engines to index and crawl content within <frame> tags, which may in turn lead to your page being excluded from search results, using these tags also negatively affects user experience.",Try to avoid using <frame> tags whenever possible.,NA,NA,NA,NA,NA,default_config.seospiderconfig,Internal:All
Orphaned pages (Google Analytics),Notices,Crawlability,"A webpage that is not linked to internally is called an orphaned page. It is very important to check your website for such pages. If a page has valuable content but is not linked to by another page on your website, it can miss out on the opportunity to receive enough link juice. Orphaned pages that no longer serve their purpose confuse your users and, as a result, negatively affect their experience. We identify orphaned pages on your website by comparing the number of pages we crawled to the number of pages in your Google Analytics account. That's why to check your website for any orphaned pages, you need to connect your Google Analytics account.","Review all orphaned pages on your website and do either of the following:
- If a page is no longer needed, remove it
- If a page has valuable content and brings traffic to your website, link to it from another page on your website
- If a page serves a specific need and requires no internal linking, leave it as is",NA,NA,NA,NA,NA,default_config.seospiderconfig,Internal:All
External pages or resources with 403 HTTP status code,Notices,"HTTP Status, Links, Crawlability","This issue is triggered if a crawler gets a 403 code when trying to access an external webpage or resource via a link on your site. A 403 HTTP status code is returned if a user is not allowed to access the resource for some reason. In the case of crawlers, this usually means that a crawler is being blocked from accessing content at the server level.","Check that the page is available to browsers and search engines. To do this, follow a link in your browser and check the Google Search Console data.
- If a page or resource is not available, contact the owner of the external website to restore deleted content or change the link on your page
- If a page is available but our bot is blocked from accessing it, you can ask the external website owner to unblock the page, so we can check all resources correctly. You can also hide this issue from your list.",NA,NA,NA,NA,NA,default_config.seospiderconfig,Internal:All
Resources formatted as page links,Notices,Crawlability,"We detected that some links to resources are formatted with <a href> HTML element. An <a> tag with a href attribute is used to link to other webpages and must only contain a page URL. Search engines will crawl your site from page to page by following these HTML page links. When following a page link that contains a resource, for example, an image, the returned page will not contain anything except an image. This may confuse search engines and will indicate that your site has poor architecture.","Review your links. Replace <a href> links with tags necessary for specific resources. For example, if you’d like to add an image, use an <img> tag with an alt attribute describing the contents of your image.",NA,NA,NA,NA,NA,default_config.seospiderconfig,Internal:All
Broken external JavaScript and CSS files,Notices,"HTTP Status, Crawlability","If your website uses JavaScript or CSS files that are hosted on an external site, you should be sure that they work properly. Any script that has stopped running on your website may jeopardize your rankings, since search engines will not be able to properly render and index your webpages. Moreover, broken JavaScript and CSS files may cause website errors, and this will certainly spoil your user experience.",Contact the website owner and ask them to fix a broken file.,NA,NA,NA,NA,NA,default_config.seospiderconfig,Internal:All
Broken internal JavaScript and CSS files,Error,"HTTP Status, Crawlability","A broken JavaScript or CSS file is an issue that should be watched out for on your website. Any script that has stopped running on your website may jeopardize your rankings, since search engines will not be able to properly render and index your webpages. Moreover, broken JS and CSS files may cause website errors, and this will certainly spoil your user experience.",Review all broken JavaScript and CSS files hosted on your website and fix any issues.,NA,NA,NA,NA,NA,default_config.seospiderconfig,Internal:All
Too many JavaScript and CSS files,Warnings,Site Performance,"This issue is triggered if a webpage uses more than a hundred JavaScript and CSS files.
Each time a visitor navigates to a webpage, their browser first starts loading supportive files, such as JavaScript and CSS. For each file used by your webpage, a browser will send a separate HTTP request. Each request increases your page load time and affects its rendering, which has a direct impact on user experience, bounce rate and, ultimately, search engine rankings.","Review your pages to make sure that they only contain necessary JavaScript and CSS files.
If all resources are important for your page, we recommend that you combine them.",NA,NA,NA,NA,NA,default_config.seospiderconfig,Internal:All
Uncompressed JavaScript and CSS files,Warnings,Site Performance,"This issue is triggered if compression is not enabled in the HTTP response.
Compressing JavaScript and CSS files significantly reduces their size as well as the overall size of your webpage, thus improving your page load time.
Uncompressed JavaScript and CSS files make your page load slower, which negatively affects user experience and may worsen your search engine rankings.
If your webpage uses uncompressed CSS and JS files that are hosted on an external site, you should make sure they do not affect your page's load time.","Enable compression for your JavaScript and CSS files on your server.
If your webpage uses uncompressed CSS and JS files that are hosted on an external site, contact the website owner and ask them to enable compression on their server.
If this issue doesn't affect your page load time, simply ignore it.",NA,NA,NA,NA,NA,default_config.seospiderconfig,Internal:All
Uncached JavaScript and CSS files,Warnings,Site Performance,"This issue is triggered if browser caching is not specified in the response header.
Enabling browser caching for JavaScript and CSS files allows browsers to store and reuse these resources without having to download them again when requesting your page. That way the browser will download less data, which will decrease your page load time. And the less time it takes to load your page, the happier your visitors are.","If JavaScript and CSS files are hosted on your website, enable browser caching for them.
If JavaScript and CSS files are hosted on a website that you don't own, contact the website owner and ask them to enable browser caching for them.
If this issue doesn't affect your page load time, simply ignore it.",NA,NA,NA,NA,NA,default_config.seospiderconfig,Internal:All
Too large JavaScript and CSS total size,Warnings,Site Performance,"This issue is triggered if the total transfer size of the JavaScript and CSS files used on your page exceeds 2 MB.
The size of the JavaScript and CSS files used on a webpage is one of the important factors for a page's load time. Having lots of clunky JavaScript and CSS files make your webpage ""heavier"" in weight, thus increasing its load time. This in turn leads to a poor user experience and lower search engine rankings.","Review your pages to make sure that they only contain necessary JavaScript and CSS files. If all resources are important for your page, consider reducing their transfer size.",NA,NA,NA,NA,NA,default_config.seospiderconfig,Internal:All
Unminified JavaScript and CSS files,Warnings,Site Performance,"Minification is the process of removing unnecessary lines, white space and comments from the source code.
Minifying JavaScript and CSS files makes their size smaller, thereby decreasing your page load time, providing a better user experience and improving your search engine rankings.","Minify your JavaScript and CSS files.
If your webpage uses CSS and JS files that are hosted on an external site, contact the website owner and ask them to minify their files.
If this issue doesn't affect your page load time, simply ignore it.",NA,NA,NA,NA,NA,default_config.seospiderconfig,Internal:All
Uncompressed pages,Warnings,Site Performance,"This issue is triggered if the Content-Encoding entity is not present in the response header. Page compression is essential to the process of optimizing your website. Using uncompressed pages leads to a slower page load time, resulting in a poor user experience and a lower search engine ranking.",.Enable compression on your webpages for faster load time.,NA,NA,NA,NA,NA,default_config.seospiderconfig,Internal:All
,,,,,NA,NA,NA,NA,NA,default_config.seospiderconfig,Internal:All